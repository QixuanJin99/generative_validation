{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4de20758-1b52-457d-a845-20000109f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pickle \n",
    "import cv2\n",
    "import torchxrayvision as xrv\n",
    "import skimage, torch, torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b817a1b3-3ece-4446-98c8-59311cddc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09712cfd-878e-4ec0-b65d-803f8a6565e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_devices(gpus):\n",
    "    if len(gpus) == 0:\n",
    "        device_ids = None\n",
    "        device = torch.device('cpu')\n",
    "        print('Warning! Computing on CPU')\n",
    "    elif len(gpus) == 1:\n",
    "        device_ids = None\n",
    "        device = torch.device('cuda:' + str(gpus[0]))\n",
    "    else:\n",
    "        device_ids = [int(i) for i in gpus]\n",
    "        device = torch.device('cuda:' + str(min(device_ids)))\n",
    "    return device, device_ids\n",
    "\n",
    "device, device_ids = get_devices([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefa157-76d8-4abb-9a59-9c5f7d28f0c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CXR Disease Classifier based evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "57033e0a-a8c8-43ee-98ba-f52431f6421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologies = np.array([\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \n",
    "               \"Lesion\", \"Pneumonia\", \"Pneumothorax\", \"No Finding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3d1acd9d-8e40-47cb-ab08-c1ec34f1835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mapping = {\n",
    "    \"mimic\": [0, 10, 1, 4, 14, 8, 3], \n",
    "    \"chexpert\": [0, 10, 1, 4, 14, 8, 3], \n",
    "    \"padchest\": [0, 10, 1, 4, 8, 3], \n",
    "    \"nih\": [0, 10, 1, 4, 8, 3], \n",
    "    \"all\": [0, 10, 1, 4, 14, 8, 3],\n",
    "}\n",
    "\n",
    "def convert_output(model_name, outputs): \n",
    "    new_outputs = outputs[:, output_mapping[model_name]]\n",
    "\n",
    "    if model_name == \"padchest\" or model_name == \"nih\": \n",
    "        lesion = torch.max(outputs[:, 11], outputs[:, 12])\n",
    "        new_outputs = torch.hstack((new_outputs[:, :4], lesion.unsqueeze(1), new_outputs[:, 4:]))\n",
    "\n",
    "    # Append \"No Findings\" output as last column \n",
    "    no_finding_output = outputs[:, [i for i, x in enumerate(model.pathologies) if x != '']]\n",
    "    # Max probability over all class with positive finding, then take the inverse \n",
    "    no_finding = 1. - no_finding_output.max(axis=1)[0]\n",
    "    new_outputs = torch.hstack((new_outputs, no_finding.unsqueeze(1)))\n",
    "    return new_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cfe6a60e-9b82-4601-98a6-7ee6802cb90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XRV-DenseNet121-densenet121-res224-all"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122d9ca1-d90a-4948-9477-ebac645e13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add810c3-1c64-4f97-ad2b-e1be9feb414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting XRayResizer engine to cv2 could increase performance.\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                            xrv.datasets.XRayResizer(512), \n",
    "                                           torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1cf07adb-ac42-4714-a76a-fd747cc2c22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:00<00:00,  1.21s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.30s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:42<00:00,  1.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:35<00:00,  1.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:12<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:07<00:00,  1.35s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.34s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:59<00:00,  1.19s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.50s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.30s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  8.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.31s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.31s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:04<00:00,  1.29s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  7.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:12<00:00,  1.45s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:11<00:00,  1.43s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  7.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:54<00:00,  1.09s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.48s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:53<00:00,  1.07s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.32s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  8.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:11<00:00,  1.43s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:36<00:00,  1.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.27it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:14<00:00,  1.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:09<00:00,  1.39s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "num_images = 10\n",
    "checkpoints = np.arange(500, 5001, 500)\n",
    "dataset_name = \"mimic\"\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "results = {}\n",
    "for checkpoint in checkpoints: \n",
    "    print(\"checkpoint {}\".format(checkpoint))\n",
    "    \n",
    "    file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/cxr_finetune_sd_{dataset_name}_base/checkpoint-{checkpoint}\"\n",
    "    unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "    \n",
    "    pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.float16)\n",
    "    pipe.to(\"cuda\")\n",
    " \n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for i, pathology in enumerate(pathologies): \n",
    "        prompt = f\"a radiograph from dataset {dataset_name} with conditions {pathology}\"\n",
    "        images = pipe(prompt=prompt, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            image = xrv.utils.normalize(np.array(image), maxval=255, reshape=True)\n",
    "            images_t.append(transform(image))\n",
    "        images_t = torch.stack(images_t)\n",
    "        images_t = torch.permute(images_t, (0, 2, 1, 3))\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images_t)\n",
    "        outputs = convert_output(\"all\", outputs)\n",
    "        \n",
    "        labels = np.zeros((num_images, 8))\n",
    "        labels[:, i] = 1\n",
    "    \n",
    "        all_outputs.append(np.array(outputs))\n",
    "        all_labels.append(labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    results[checkpoint] = {}\n",
    "    auc = roc_auc_score(all_labels, all_outputs)\n",
    "    task_aucs = roc_auc_score(all_labels, all_outputs, average=None)\n",
    "    \n",
    "    results[checkpoint]['auc'] = auc\n",
    "    results[checkpoint]['task_aucs'] = task_aucs\n",
    "    results[checkpoint]['task_outputs'] = all_outputs\n",
    "    results[checkpoint]['task_targets'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b51b7af-9680-4795-bdc8-f6b91009e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/mnt/scratch-lids/scratch/qixuanj/cxr_finetune_sd_{dataset_name}_base/eval_checkpoints_densenet121-res224-all.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results, f)cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f981430-3f78-41d2-9c04-d2158dc994ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aucs = [results[c]['auc'] for c in checkpoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2168abf-499e-46a5-bf9d-b8dd033fa509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlSUlEQVR4nO3dd3zV1f0/8Ncdufdm3ZtF9mSFEZJAICE4cFBxglYrWipUv1q1uApSpa1StS2oLVotFWuL2J+tOKqCC0UUFJkCGawwssleN/sm997z++PmXogkIePe+7nj9Xw88mi543PfN1eSF+e8zzkyIYQAERERkReRS10AERERkbMxABEREZHXYQAiIiIir8MARERERF6HAYiIiIi8DgMQEREReR0GICIiIvI6SqkLcEVmsxkVFRUIDAyETCaTuhwiIiIaBCEEWlpaEB0dDbl84DEeBqA+VFRUIC4uTuoyiIiIaBjKysoQGxs74GMYgPoQGBgIwPIN1Gq1EldDREREg9Hc3Iy4uDjb7/GBMAD1wTrtpdVqGYCIiIjczGDaV9gETURERF6HAYiIiIi8DgMQEREReR0GICIiIvI6DEBERETkdRiAiIiIyOswABEREZHXYQAiIiIir8MARERERF6HAYiIiIi8DgMQEREReR0GICIiIvI6DEBERERuQAiBNoNR6jI8BgMQERGRG1j92XGkPvUFNudWSF2KR2AAIiIicnH55Xr849tCmMwCv3k/H6X17VKX5PYYgIiIiFyY2SzwxKbDEAJQymVoNRjx0MZD6DaZpS7NrTEAERERubD3DpQjp6wJAWol3rkvG4EaJXLKmvDStpNSl+bWGICIiIhcVFN7F1ZvOQ4AeGTOOEyLD8aqH08BAKz9+hT2FtZLWZ5bYwAiIiJyUX/+ogANbV0YHxGAxbMSAQDXp0bjJxmxMAvgV2/nQN/eLW2RbooBiIjIziqaOlBY2yp1GeTm8sv1+M/eUgDA0/NT4KM4+yv79/MmIzHUDxX6Tqz4IA9CCKnKdFsMQEREdtRmMGLe377DtS99i4qmDqnLITdlNgv8rqfx+cb0aMwcHdrrfn+1En+9bSqUchk+za/Cu9+XS1Sp+2IAIiKyo7f2laKu1YDObjM+4n4tNEzvfF+G3J7G599cO7HPx6TFBWHZVckAgJWbj3DUcYgYgIiI7KTLaMY/vy2y/Zkb1tFwNLV34dlzGp/DtZp+H3vvpaMxa0woOrpNeHhjDrqMXBo/WAxARER28mHOGVQ1dyIsQA2lXIYjFc04VcN/ldPQPP95ARrbu5EcEWhrfO6PXC7DmlvTEeTng/wzevxla4FzivQADEBERHZgNgus23EaAPCLS5Nw6fhRADgKREOTV96E/+6zNj5P7tX43J9InQarf5wKAHh1RyF2nqxzaI2eggGIiMgOvjhajcLaNmg1StyeGY95adEAgM05Z7hChwbFbBZ44kNL4/NNU2OQ9YPG54FcnRKJn2bFAwCWvpODhrYuR5XpMRiAiIhGSAiBV3pGfxZlJyJQ44MfTYqAxkeO4vp25J/RS1whuYO3vy9DbrkegWolVlw7YcjPf+K6SRgzyh81LQY89j8ujb8QBiAiohHaXViP3LImqJVy/PyiRACWZcpzJkYAADblcBqMBtbYdrbx+Vc/Go/wwP4bn/vjq1LgpdunQqWQY+vRatseQtQ3BiAiohF6Zbtl9GfBjDiEBahtt89PjwEAfJxXAZOZ/xqn/j3/RQGa2rsxITIQi7IThn2dydE6/Ppqy9L4Zz4+ipPVLfYq0eMwABERjcDhM3p8e7IOCrkM91wyutd9l44Pg1ajRHWzAXuLeGYT9S23rAlv7Tu747NyEI3PA7nrIksTvsFoxoNvHUJnt8keZXocBiAiohGw9v7ckBqFuBC/XveplQpcOyUKALgpIvXJZBZ4omfH5x9PjUFmUsiIrymXy/Dnn6Qi1F+F41Uttqk16o0BiIhomIrq2vBZfiUA4L7LxvT5GOtqsE/zq7hJHZ3n7f1lyOtpfH58GI3P/QkP1OD5n1iWxr/+XTG+Lqix27U9BQMQEdEw/eObQpgFcMWEcEyI1Pb5mKzRoQgPVEPf0Y1vTtQ6uUJyZY1tXXjuc8vozNKrhtf4PJArJkTg5z0bKS5/Nxe1LQa7Xt/dMQAREQ1DTXMn/nfAcgDlL/sZ/QEAhVyG61Mto0CbOA1G53ju87ONz3fMHH7j80Aev2YCkiMCUdfahUffzYWZzfg2DEBERMPwr++K0GUyY0ZiMKYnDty3MT/dEoC+PFqNNoPRGeWRi8spa8LG/ZbG52duHHnjc380Ppal8WqlHDtO1GLDrmKHvI47YgAiIhoifUc3/rPH8svr/gFGf6xSY3VICPVDR7cJXx6rdnR55OJMZoEnrY3P02Iw4wIBeqSSIwPxu+ssJ8qv/uw4jlU2O/T13AUDEBHREL25pwStBiOSIwJxeXL4BR8vk8kw33Y0BqfBvN3G/aW2xucV10x0ymv+bGYC5kwMR5fJjIfeOoSOLi6NZwAiIhqCzm4TXv+uCIBl9Ecmkw3qefN6psF2nKhFI89p8loNbV14bovlxPZlV43HqED1BZ5hHzKZDM/enIpRgWqcrGnFHz896pTXdWUMQEREQ/DugXLUtXYhNtgX16dGDfp5Y8MDMSlKC6NZ4LPDVQ6skFzZc1uOQ9/RjYlRWvzMQY3P/QkNUGPNrWkAgDf3lOKLI9793yEDEBHRIBlNZvzjG8vGh7+4dPSQG1eto0Cbcs7YvTZyfYdKG/H292UAgGfmT3ZY4/NALhk3Cr+41LJj+WP/y0N1c6fTa3AVDEBERIP0SX4lyho6EOqvwk8y4ob8/Bt6+oD2FTegUt9h7/LIhVkan49ACODmabEXXDnoSI9elYzJ0Vo0tndj6Ts5Xrs0ngGIiGgQhBC2Q0/vvCgRvirFkK8RE+SLGYnBEAL4OLfS3iWSC3trXynyz+gRqFHi8Wvst+PzcKiUcrx0+1T4+ijw3al6vPZtoaT1SIUBiIhoELafqMXxqhb4qxS4Y2bisK8zr+eE+M3cFNFr1Lca8PznlsbnR69Kdlrj80DGjArAyhsmAQCe/7wAeeVN0hYkAQYgIqJBsI7+LJyZAJ2fz7Cvc21KJBRyGfLP6FFY22qv8siFPbelAPqObkyK0mJhVrzU5dgsmBGHa1IiYTQLPLwxx+s26WQAIiK6gAMlDdhX1ACVQo7/uzhpRNcKDVDjknFhADgK5A0Ontv4fKM0jc/9kclkWPXjKYjSaVBU14anP/KupfGu80kQEbko6+jPj6fFIEI78gMr552zKaIQ3tmA6g2sOz4DwC0ZschIkK7xuT9BfiqsuTUdMhnw9vdl+CTPe3rTGICIiAZQUNWCL4/VQCaDbfnwSF01ORJqpRyFdW04UsFjCTzVf/eV4vCZZpdofB5I9phQ24G+K97Pw5km71ihyABERDSAV3dYRn+uSYnE6FEBdrlmgFqJORMjAHBPIE9V32rA81uOAwCWz01GWID0jc8DeWTOeKTFBaG504hfbcyByQuWxjMAERH1o7yxHZt6+nTum33hQ0+Hwrop4ke5lV67D4sne3bLcTR3GjE5WouFWc7d8Xk4fBRyvHRbOvxVCuwrbsAr209JXZLDMQAREfXjn98WwWQWuHhsGFJjg+x67cuSRyFQo0RVcyf2FTfY9dokrQMljXjn+3IAwNPzU6CQD+68OKklhPrj6fkpAIAXvjyJg6WNElfkWAxARER9qG81YOP+UgCWQ0/tTa1U4JqUSABcDeZJzm18vnV6LDISgiWuaGh+PC0G89KiYTILPLzxEFo6u6UuyWEYgIiI+vDGrmJ0dpuRGqvDrDGhDnmNeWmWTRE/za9El9HskNcg5/rv3hIcqWiGVqPEY1e7buNzf2QyGf5wUwpig31R1tCBJzcdkbokh2EAIiL6gVaDEW/sLgEA3D97DGQyx0xhZI8JRViAGk3t3dh5qtYhr0HOU3fOjs/L5yYj1MUbn/uj1fjgxQXpkMuADw6dwYeHPLNRnwGIiOgHNu4rhb6jG6PD/HHV5EiHvY5CLsP1qVEAgE05nAZzd89+drbx+adu0Pg8kOmJIXjoynEAgN99eBil9e0SV2R/DEBEROcwGE22wyHvnT3a4Q2s83tWg31xpBrtXd51FIEnOVDSgHcPWBqfn7nRfRqfB/LA5WMxPSEYrQYjHn77EIwmz5qmlTwArV27FomJidBoNMjKysK+ffsGfHxTUxOWLFmCqKgoqNVqjB8/Hp9++umIrklEZLXpUAWqmw2I0Kpx49QYh79eelwQ4kP80NFtwpfHahz+emR/JrPAEx9aemUWTI/DtHj3anzuj1Ihx4u3pSNQo8Sh0ia8tO2k1CXZlaQB6O2338bSpUuxcuVKHDx4EGlpaZg7dy5qavr+IdDV1YUf/ehHKC4uxnvvvYeCggK89tpriImJGfY1iYisTGaBdd9YNj68++LRUCsVDn9NmUx2ztEYntlr4en+s7cERystjc+/vjpZ6nLsKjbYD3+8aQoA4G9fn8K+Is/ZskHSALRmzRrcc889uPPOOzFp0iSsW7cOfn5+WL9+fZ+PX79+PRoaGvDhhx/ioosuQmJiImbPno20tLRhXxMADAYDmpube30RkffZerQKhbVt0GqUuN2Jp3ZbN0XccaIWTe1dTntdGrlejc9XT3DbxueBzEuLxs3TYmEWwCMbD0Hf7hlL4yULQF1dXThw4ADmzJlzthi5HHPmzMHu3bv7fM7mzZuRnZ2NJUuWICIiAikpKfjTn/4Ek8k07GsCwKpVq6DT6WxfcXFxdnqXROQuhBC2Q08Xz0pEgFrptNceHxGICZGB6DYJfHa4ymmvSyO3+rPjaOk0IiVGi59mOi80O9tT8ycjIdQPFfpO/ObDfI84xFeyAFRXVweTyYSIiIhet0dERKCqqu8fAIWFhXjvvfdgMpnw6aef4oknnsBf/vIX/OEPfxj2NQFgxYoV0Ov1tq+ysrIRvjsicje7T9cjt1wPjY8cP5+V6PTXt44CbeZqMLfxfXED3rM2PrvRjs/DEaBW4q+3TYVSLsMneZW2hm93JnkT9FCYzWaEh4fjH//4BzIyMrBgwQL89re/xbp160Z0XbVaDa1W2+uLiLzLKz2Hni6YHifJNMYNqZYAtKeoHlX6Tqe/Pg2N0WTGEz2bBN42Iw5TPaTxeSDpcUFYetV4AMDvNx9BYW2rxBWNjGQBKCwsDAqFAtXV1b1ur66uRmRk3/tuREVFYfz48VAozjYmTpw4EVVVVejq6hrWNYmI8sv1+PZkHRRyGe6+ZLQkNcSF+CEjIRhCAB/ncRTI1b25pwTHKpuh8/XBr91wx+fhuvfSMZg5OgTtXSY8vDHHrXcwlywAqVQqZGRkYNu2bbbbzGYztm3bhuzs7D6fc9FFF+HUqVMwm89+w0+cOIGoqCioVKphXZOIaF3P6M+8tGjEhfhJVod1TyCeDebaalsM+MvWEwAsOz6H+Kskrsh5FHIZXliQDp2vD/LP6LGm5/vgjiSdAlu6dClee+01vPHGGzh27Bjuv/9+tLW14c477wQALFq0CCtWrLA9/v7770dDQwMefvhhnDhxAp988gn+9Kc/YcmSJYO+JhHRuYrq2vDp4UoAlo0PpXTtlCgo5DLkletRVNcmaS3UP2vj85QYHW734Mbn/kTpfPHszZal8a9+cxrfnaqTuKLhcd4yhz4sWLAAtbW1ePLJJ1FVVYX09HRs2bLF1sRcWloKufxsRouLi8Pnn3+OX/3qV0hNTUVMTAwefvhhPPbYY4O+JhHRuf7xzWkIAVw5IRwTIqXt/wsLUOOisWH45kQtNudU4OE54ySth863v7gB/ztYDpnMc3Z8Ho6rU6Jwe2Y83tpXiqXv5OCzhy91u5EwmfCEtWx21tzcDJ1OB71ez4ZoIg9W3dyJS579Gl0mM967LxvTE0OkLgnvHSjHo+/mYvQof2xbOtthB7HS0BlNZlz/8k4cr2rB7ZlxWPXjVKlLklR7lxHXv7wThbVt+NGkCPzjjgzJ/3sdyu9vt1oFRkRkT+t3FqHLZMaMxGCXCD8AMHdyBFRKOQpr23CkgpuyupL/t6cEx6taEOTng+VzvafxuT9+KiVeum0qfBQybD1ajf/uK5W6pCFhACIir6Rv78abe0oAAPdfNkbias4K1PjgygnhAICP2AztMmpbDFjzhXc2Pg8kJUaHx3pWwT3z8VGcrG6RuKLBYwAiIq/05t4StHWZkBwRiMuTw6Uup5dzV4OZzexScAWrPjuGFoMRqbE63DbD+xqfB3LXRUm4ZFwYOrvNeGhjDjq7TVKXNCgMQETkdTq7TVi/swiAZfRH6r6FH7osORyBaiUq9Z34vqRR6nK83r6iBrx/8Iyl8dnDd3weDrlchr/8JA0h/iocq2zGc1sKpC5pUBiAiMjrvPt9GerbuhAb7IvrU6OkLuc8Gh8F5qZYNm/dxBPiJWU0mfHkpsMAgNtmxCMtLkjaglxUuFaD52+xNIWv/64I2wtqJK7owhiAiMirGE1mvPpNIQDg3ktHQ6lwzR+D89Is02Cf5lei2+S+u+26u3/vPtv4/Ou5yVKX49KunBiBxdkJAIBH381FbYtB4ooG5pp/84mIHOST/EqUN3Yg1F+Fn0yPk7qcfs0aE4qwABUa27ux86R7bjTn7mpaOvFCz07Hj109AcFsfL6gFddORHJEIOpau7D8vVyXPjWeAYiIvIYQAq9stxx7cdfFSdD4KC7wDOkoFXJcN8UyPcejMaSx+tPjaDEYkRarwwIXDsuuROOjwEu3T4VKKcf2glps2FUsdUn9YgAiIq+xvaAWx6taEKBW4mczE6Qu54LmpccAAD4/UoWOLvdYWeMp9hbW4/1Dlsbnp+enQM7G50FLjgzEb6+dCABY9elxHKt0zf2sGICIyGtYR38WZsVD5+sjcTUXNi0+CLHBvmjvMmHb8Wqpy/Ea3SYzntx0BABweyYbn4djUXYCrpgQji6TGQ+9dcgll8YzABGRV/i+uAH7ihugUshx18VJUpczKDKZzNYMvSmH02DO8u/dJSiobkGwnw+WX8XG5+GQyWR4/pZUjApU42RNK/74yTGpSzoPAxAReQXr6M/NGTGI0Gokrmbw5vVsirijoBb69m6Jq/F8Nc1sfLaX0AA1/vKTNACWY0S2HnWtUUwGICLyeMermrHteA1kMuAXl7rOsReDMSFSi+SIQHSZzNhypFLqcjzenz49hlaDEWlxQbiVjc8jdun4Ubi7Z8T11+/lorq5U+KKzmIAIiKP9+oOy74/16ZEISnMX+Jqhm7eOUdjkOPsLazHhzkVPTs+T2bjs50svzoZk6K0aGzvxtJ3clzmeBcGICLyaGUN7bbgcN9s9xr9sbL2Ae06XY8aF/oXtCc5t/H5p5nxSI0NkrYgD6JWWpbGa3zk+O5UPf65s1DqkgAwABGRh/vnt4UwmQUuGReGKbE6qcsZlrgQP0yND4IQwMd5nAZzhDd2FZ9tfOaOz3Y3NjwAK2+YDAB4/vMC5JfrJa6IAYiIPFhdqwEb95cBAO5309Efq/nW1WCcBrO76uZOvPjlSQDA49dMQJAfG58d4bYZcZg7OQLdJoGHNh5Cm8EoaT0MQETksd7YVQyD0Yy0WB2yx4RKXc6IXJcaDbkMyC1rQkl9m9TleBRr43N6XBB+ksHGZ0eRyWRY/eNURGo1KKprw9MfHZW0HgYgIvJIrQYj3ujZhv/+y8ZAJnPvhtZRgWpcNDYMALCZewLZzZ7CemyyNT5zx2dHC/ZXYc2CNERo1bguNUrSWhiAiMgjvbW3FM2dRowe5Y+rJkVKXY5d3HDONJgrHzLpLiyNz4cBWHYHd9ceMXcza0wYdiy/HJeOHyVpHQxARORxDEaTbaXJfZeO8Zh/1V+dEgmVUo5TNa04VtkidTlu741dxThR3YoQfxUe5Y7PTuUKBxEzABGRx/nw0BlUNxsQqdVg/tRoqcuxG63GB5cnW/7VzD2BRqb6nB2fH7+ajc/eiAGIiDyKySxsGx/efUkS1Erp/6VpT/N7Toj/KLfCZTaUc0d//OQY2rpMmBofhFsyYqUuhyTAAEREHuWLI1UorGuDztcHt2XGS12O3V0xIRwBaiXONHXgYGmj1OW4pV2n67A5twJyNj57NQYgIvIYQgi8ssNy6Oni7AQEqJUSV2R/Gh8FrpocAYAnxA9Ht8mMlT07Pi/MSkBKDBufvRUDEBF5jF2n65FXrofGR47FsxKlLsdhrEdjfJpfiW6TWeJq3MuG74pxsoaNz8QAREQe5JXtltGf22bEIzRALXE1jnPR2DCE+qtQ39aF707VSV2O26jSd+LFL3san6+ZAJ2fj8QVkZQYgIjII+SVN2HnqToo5DLcfUmS1OU4lI9CjmunWDaR42qwwfvjp5bG52nxQbhlGhufvR0DEBF5hHU9vT/z06IRG+wncTWONz/dMg32+eEqdHabJK7G9e06VYePehqfn2bjM4EBiIg8QGFtKz47XAUAuNfNDz0drGnxwYgJ8kVblwlfHa+RuhyX1mU048nNlsbnn81k4zNZMAARkdv7xzeFEAKYMzEcyZGBUpfjFHK57OzRGDlnJK7Gta3/rginaloR6q/Csh+x8ZksGICIyK1V6Tvxv4PlACyHnnoT62qwrwtqoe/olrga15RX3oQ1X7Dxmc7HAEREbm39d0XoNglkJoYgIyFE6nKcamJUIMaFB6DLaMbnR6qkLsfl6Du6seS/B9FlMuOqSRHc8Zl6YQAiIrelb+/Gf/aUAPC+0R8AkMlktlGgj7garBchBB57Lw9lDR2IDfbF87ekQSZj4zOdxQBERG7r/+0pRluXCRMiA3FZzyGh3mZez2qw707VoaalU+JqXMcbu4qx5UgVfBQyrP3pNE590XkYgIjILXV0mfD6d8UALKM/3vqv+4RQf6TFBcEsgE/zKqUuxyXklTfhj58eAwD85tqJSIsLkrYgckkMQETklt49UIb6ti7EBvviup5NAb3VfOtqME6D2fp+uk0CcydH4OcefCQKjQwDEBG5nW6TGa/uKAQA3HvpaCgV3v2j7PrUKMhlwKHSJpTWt0tdjmSEEPj1e7koa+hAXIgvnmPfDw3Au39qEJFb+iSvEmeaOhDqr8JPpsdJXY7kwrUaZI8JBQB8lOe9o0AbdhXj8yPVZ/t+fNn3Q/1jACIityKEsB16etfFSdD4KCSuyDVYV4NtzvHOAJRb1oQ/9fT9/PbaiUiNDZK2IHJ5DEBE5Fa+LqhBQXULAtRK/GxmgtTluIyrJ0dBpZCjoLoFx6uapS7HqfTtZ/t+rp4cicXs+6FBYAAiIrfy968toz8LZ8ZziuMcOj8fzO7ZCsCbRoGEEFj+Xi7KGy19P8/eksq+HxoUBiAaMiEEdp2uQ1N7l9SlkJfZX9yA70saoVLI8X8XJUldjsuxnhC/ObcCQgiJq3GO178rxhdHq6FSyPH3n2YwFNOgMQDRkG07VoOfvrYXv/3wsNSlkJex9v7cnBGLcK1G4mpcz5UTIuCvUqC8sQMHS5ukLsfhcsqasOqznr6f6yZiSixPeafBYwCiIdt5qg4A8E1BLUxm7/hXJknvWGUzvjpeA7nMsvSdzuerUuCqyZEAgM0efkK8vr0bS/5j6fu5dkokFmWzH4yGhgGIhiyvvAkA0GIwel2zJUnn1R2W0Z9rpkQhMcxf4mpcl3U12Cf5lTCazBJX4xhCCDz6Xi7ONHUgPsQPq29m3w8NHQMQDUm3yYwjFWdDz76iBgmrIW9R1tCOj3qOebh/tvcdejoUF48LQ7CfD+pau7DrdL3U5TjE+u+KsbWn72ftT6dBq2HfDw0dAxANSUFVCwzGs/+q3F/MAESO99q3hTCZBS4ZF4aUGPZ5DMRHIce1PUeDbPbAozFyypqwuqfv53fXs++Hho8BiIYkt2f6K7jnZOV9RQ1es9qEpFHXasDb+8sAWA49pQubnx4DAPj8cBU6u00SV2M/Te1dtr6f66ZE4Q7uA0UjwABEQ5JXpgcA3JIRC5VSjrrWLhTWtUlcFXmyDd8Vw2A0Iy0uCNmjQ6Uuxy1MTwhGlE6DFoMR2wtqpC7HLoQQePTdPJxp6kBCqB9W3TyFfT80IgxANCTWEaAZiSFIjwsCAOxnHxA5SEtnN/69uxiApfeHv/AGRy6X2ZqhN3nIpoj/2lmEL4+x74fshwGIBq29y4gT1S0AgLS4IGQlhQBgIzQ5zlv7StHcacToUf64alKE1OW4lRt6AtC24zVo6eyWuJqROVTaiNWfHQcAPHH9RPaBkV0wANGgHalohlkAkVoNIrQazEi0BKC9DEDkAAajCf/8tggAcN/sMZDLOfozFJOjtRgzyh9dRjM+P1ItdTnD1tTehQf+ewhGs6Xvh+e/kb0wANGg5ZY1AQBSe1ZdTEsIhkIuw5mmDpxp6pCwMvJEHxw8g5oWAyK1GtzY09RLgyeTyTAvzfJ9c9fVYJa+n1xb389q9v2QHTEA0aDlllsaoNN6en8C1EqkRGsBsA9IakIIj1qNZzILvPpNIQDg7kuSoFLyR9VwzOs5G+y7U3WoazVIXM3QWfp+amx9P4Hs+yE7UkpdALkP6w7QabFBtttmJIYgt1yPfcUNuHEq/5UuhZbObtzw8k5U6DsRpdP0fPkiUqdBtE6DSJ2v7fYQf5Vb/Av68yNVKKprg87XB7dnxktdjttKCvNHaqwOeeV6fJpfiUXZiVKXNGgHz+37uWES+37I7hiAaFAa27pQUt8OAL02HstMCsE/dxaxEVpC356sQ3HPZ1NS3277nPqiUsoRpdMgUqtBdJAlJFkDk6uEJCGE7dDTxbMS4a/mj6mRmJcWjbxyPTblVLhNAGpq78ID/zkIo1ng+tQo/CyLIZjsjz9ZaFDyzlimv5LC/KHzPTsMbW2EPlXTivpWA0ID1JLU58129xx3cEtGLG6dHodKfQeq9J2o1HeiUt/R87+dqGs1oMtoHlRIitRqzo4mBfn2CkmROg1CHRiSvjtVj/wzemh85Pj5rESHvIY3uSEtGn/89BgOlDSirKEdcSF+Upc0ICEElr2Tiwp9JxJD/bDqx+z7IceQPACtXbsWzz//PKqqqpCWloaXX34ZmZmZfT52w4YNuPPOO3vdplar0dnZaftza2srHn/8cXz44Yeor69HUlISHnroIdx3330OfR+eztoAnfaDbeeD/VUYHxGAE9Wt2F/ciKtTIiWozrvtOl0HAPjRpAhk9mxN0JcuoxnVzZ2oau5ERVPvkFSl70TFOSGptKEdpQ0DhCSF/JzRI8s0W3RQ75GlED/VsFZuvbLjFADgthnxCPFXDfn51FuEVoOZSaHYXViPj/Iq8MvLxkpd0oD++W0Rth2vgUopx9/Y90MOJGkAevvtt7F06VKsW7cOWVlZePHFFzF37lwUFBQgPDy8z+dotVoUFBTY/vzDfxksXboUX331Fd58800kJibiiy++wC9/+UtER0dj3rx5Dn0/nsza/5N6Tv+PVWZSCE5Ut2JfUQMDkJPVNHfidG0bZDJgZtLAuySrlHLEhfgNOAJwbkiq1Heisqmj75BkGnxI6qsXKUrni6ig80NSblkTvjtVD6VchrsvSRr6N4T6ND89GrsL67E5x7UD0IGSRjy7xdL38+T17Pshx5I0AK1Zswb33HOPbVRn3bp1+OSTT7B+/Xo8/vjjfT5HJpMhMrL/X7K7du3C4sWLcdlllwEAfvGLX+DVV1/Fvn37GICGSQiBnLLeK8DONSMxBG/uKeXBqBLYXWiZ/pocrYXOb+T/Uh5sSKpp6bRNrVlDUtU5U261QwhJETq1bXrtdG0rAMvqpdhg156qcSfXpEThiU2HcbyqBSeqWzA+IlDqks7T2NaFB/9r6fu5IS0aC9n3Qw4mWQDq6urCgQMHsGLFCtttcrkcc+bMwe7du/t9XmtrKxISEmA2mzFt2jT86U9/wuTJk233z5o1C5s3b8Zdd92F6OhobN++HSdOnMALL7zQ7zUNBgMMhrNLRJubm0f47jyLtX9EKZdhcs+y93NZp12OVOjR0tnNIWsnsvb/zBoT5rTXVCnliA32GzCg/DAkVek7UNHUd0gqa+hAWUPvfaTum81DT+1J5+eD2ePD8eWxamzOqcCjc5OlLqkXs1lg2buWvp+kMH/86aYU9v2Qw0kWgOrq6mAymRAR0Xt7+4iICBw/frzP5yQnJ2P9+vVITU2FXq/Hn//8Z8yaNQtHjhxBbGwsAODll1/GL37xC8TGxkKpVEIul+O1117DpZde2m8tq1atwlNPPWW/N+dhrNNf4yMCofFRnHd/lM4X8SF+KG1ox4GSRlyW3Pf0Jdnfrp4A5GqHhA4mJHWbeqbbeqbWqnqC0ZQYnUuOULi7eenR+PJYNTblnsGyq8a7VMD4585CfGXr+5nKf0SRU0jeBD0U2dnZyM7Otv151qxZmDhxIl599VU888wzACwBaM+ePdi8eTMSEhLwzTffYMmSJYiOjsacOXP6vO6KFSuwdOlS25+bm5sRFxfn2DfjRn64AWJfZiSGoLShHfuLGxiAnKS80TK9pJDLMGOA5mdX5aO4cEgi+5kzMRx+KgXKGjpwqKwJ0+KDpS4JAHCgpAHPbrH0df7+hsmYHM2+H3IOyQJQWFgYFAoFqqt7n1FTXV09YI/PuXx8fDB16lScOmVZNdLR0YHf/OY3+OCDD3DdddcBAFJTU5GTk4M///nP/QYgtVoNtZrLt/vT3wqwc2UlheB/B8u5H5ATWae/UmN1COBeOXQBfiolfjQpAptyKrA5p8IlAlBjm+WcL5NZYF5aNG7P5D88yXkk219epVIhIyMD27Zts91mNpuxbdu2XqM8AzGZTMjPz0dUVBQAoLu7G93d3ZDLe78thUIBs9lsv+K9iNkskN8zAtTXCjAr6whEbpkend0mZ5Tm9awN0LPGuNb0F7mu+T1HY3ycVwmjSdqfida+n0pr3w/3+yEnk/SAnaVLl+K1117DG2+8gWPHjuH+++9HW1ubbVXYokWLejVJP/300/jiiy9QWFiIgwcP4mc/+xlKSkpw9913A7AskZ89ezaWL1+O7du3o6ioCBs2bMC///1v3HTTTZK8R3dXWNeGFoMRGh85xkcE9Pu4xFA/jApUo8tkto0YkeMIIWwjQNmjndcATe7t4rGjEOTng7pWA/YUSjta+49vLX0/aqXlnC+OYpKzSfpf3IIFC1BbW4snn3wSVVVVSE9Px5YtW2yN0aWlpb1GcxobG3HPPfegqqoKwcHByMjIwK5duzBp0iTbYzZu3IgVK1Zg4cKFaGhoQEJCAv74xz9yI8RhsjZAp0TroFT0n5dlMhkyk0LwSV4l9hU1IMvFmnI9TUl9Oyr1nVAp5MhIkH4qg9yDSinHtVOi8N+9pdiUcwYXj5MmPH9f3IDnP+/p+5k3GZP6WF1K5GiSR+4HHngADzzwQJ/3bd++vdefX3jhhQGXswNAZGQkXn/9dXuV5/XyBtEAbZWZ2BOAuB+Qw1lXf6XHB8FXdf7KPKL+zEuLxn/3lmLLkSo8c2NKnys7HamhrQsPvmXp+5mfHo3bZrDvh6Qh6RQYub6cnums1AEaoK2s+wEdKGmUvL/A07H/h4YrMzEEkVoNWjqN2F5Q69TXNpsFlr2Tg0p9J0aH+eOPN7Hvh6TDAET96jKacbTSsilk2gAN0FbJEYHQapRo7zLhSAU3k3SU3v0/DEA0NHK5DDekWRaOfJRb4dTXfvWbQnxdUGvp+1nIvh+SFgMQ9augqgVdRjN0vj5ICL3wXi1yucx2OjyPxXCcUzWtqGs1QOMjR3p8kNTlkBuanx4DAPjyWDVaOrud8pr7ixvw5y8sfT9PzZuMiVHs+yFpMQBRv3JtB6DqBj1MbZ0G28v9gBzG2v8zPSEEaiX7f2joJkdrMTrMHwajGVuPVl/4CSPU0NaFB3v2+7kxPRoL2PdDLoABiPplXQGWPogGaCvrfkD7ixtgNgsHVEW26S/2/9AwyWQyzOvZE2hTjmOnwcxmgaXv5KCquROjR7Hvh1wHAxD1K7fswhsg/lBKtA6+Pgo0tXfjVM/J3mQ/ZrPAniIGIBq5eWmWALTzVB3qWw0XePTwrfvmNLb39P38feE0+LPvh1wEAxD1qb3LiJM1LQAGPgLjh1RKOaYlBAHgNJgjHKtqRlN7NwLUSqTG8MwkGr7RowIwJUYHk1ng0/xKh7zGvqIG/OWLEwCAp+dPxoRI9v2Q62AAoj4dPtMMswCidBqEazVDeq6tEZoByO6s018zEoMH3JiSaDCso0CbHbAarL7VgId69vu5aWoMbp3Ovh9yLfwJSn3KHcL+Pz9kbYTeV9QAIdgHZE/WADRrDI+/oJG7Pi0KMhmwv7gRZ5o67HZdS99PLqqaOzFmlD/+cGMK+37I5TAAUZ/OrgALGvJzp8YFw0chQ1VzJ8oa7PdD1dsZTWbbtCL7f8geonS+yOwZsbXnnkCv7DiNHSdqofGR4+8LM9j3Qy6JAYj6lDuMFWBWvioFpvT0p/BYDPs5XNGMVoMROl8f7qFCdmPdE8heq8EsfT+W/X6enpeC5MhAu1yXyN4YgOg8DW1dtpGblGE22mYmWUYo9vWsWKKR23W6DgCQlRQChZzTCWQf16REQimX4VhlM05Wt4zoWvWtBjz41kGYBfDjqTH4yfRYO1VJZH8MQHQe6/4/o0f5Q+frM6xrZCZZTijfX9xor7K83tn+H05/kf0E+6swe/woACNrhjabBX71Ti6qmw0YM8ofz7Dvh1wcAxCdx7r/z2DO/+pPRkIIZDKgqK4NNc2ddqrMe3UZzfi+J0xmswGa7My6KeLm3IphL1x4ZcdpfMO+H3IjDEB0nrxzjsAYLp2vDyb27PnBPqCRyy1vQke3CaH+KoyPCJC6HPIwcyZGwNdHgZL6duSW64f8/L2F9Wf7fuaz74fcAwMQ9SKEsDVApw2jAfpc1uXw3A9o5Hadskx/zRwTymkFsjt/tRJzJkUAADYPsRm6rtWAhzYesvT9TIvBTzLY90PugQGIeqnQd6KutQtKuQyTRrjSiAej2s/uQksDNPt/yFHm92yK+FFeBUyDPMfPbBb41ds5qG42YGx4APf7IbfCAES95PVsgDghKhAan5GdNG7dEbqgugX69u6Rlua1OrtNOFjSBADIHs0ARI5x6fhR0Pn6oLbFgL2Fg1u9+fftp/Dtybqevp9p8FOx74fcBwMQ9ZIzgg0Qf2hUoBqjw/whBPB9CUeBhutgSSO6TGZEajVICvOXuhzyUCqlHNdOiQQwuD2B9hTWY81Wyzlfz8xPwfgI9v2Qe2EAol7ybCvA7HPQ5rnHYtDw7Dp99vR3Ti+QI93QMw322eFKGIymfh9X13POl1kAN0+LxU94zhe5IQYgsjGbBfLP9ASgETZAW1mnwbgSbPh2F54NQESOlJUUigitGs2dRuwoqO3zMaaevp+aFgPGhQfgmRsnO7lKIvtgACKbwrpWtBqM8PVRYOwo+yy1to4A5Zfr0d5ltMs1vUmbwWg7mJb9P+RoCrkM16cOfEL837+29P34+ijY90NujQGIbKwbIKbEaKFU2Oc/jdhgX0TpNDCaBQ6VNtnlmt5kf3EDjGaBuBBfxIX4SV0OeYH5PZsifnmsGm2G3v9o2X26Hi982dP3c2MKxrHvh9wYAxDZ2Pb/sUMDtJVMJmMf0AhYj7/g6A85y5QYHRJD/dDZbcbWo9W222tbzu73c0tGLG7hfj/k5hiAyMa6A2yqnfp/rBiAhs/a/zOLx1+Qk8hkMsyznRB/BsDZvp/aFgPGRwTgmfkpUpZIZBcMQATActbUsYpmAEC6HUeAACCzpxH6UFkjuoxmu17bk+nbu3G4pymdDdDkTPN6VoN9e7IODW1dWPv1Kew8Zen7WfvTafBVjWyPMCJXwABEAIDjVc3oMpkR7OeDuBBfu157bHgAQvxV6Ow221aZ0YXtLaqHWQCjR/kjQquRuhzyImPDAzA5WgujWeDpj47gxZ6+nz+w74c8CAMQATg7/TUlNsjue83IZDLMSAwGwGmwobAtf2f/D0nAOgr0YU4FzAK4dXosbmbfD3kQBiACANtS63Q7bYD4Q9b9gPZzP6BBszZAs/+HpGDdFBEAxkcE4Kl57Pshz8IARACAPDsegdGXrCTLKMb+4oZBH7TozepbDThe1QIAmDk6ROJqyBtFB/nipqkxCA9U4+8L2fdDnoc7WBFaDUacrGkFAKTGOWYEaGJUIPxVCrR0GnG8qhmTox3zOp5iT6FlpGxCZCBCA9QSV0Pe6oUF6RBC8AgW8kgcASIcPqOHEEC0ToPwQMc02yoVcmRYp8HYB3RBuwvrAAAz2f9DEmP4IU/FAEQOn/6yykriuWCDtcvW/8MARETkCAxAZFsBZq8DUPtjOxi1qBFCsA+oP9XNnSisbYNMdrZ3ioiI7IsBiGwrwNIctALMKjVWB5VSjrpWA4rq2hz6Wu7MuvorJVoHnZ+PxNUQEXmmQQegiooKPProo2hubj7vPr1ej+XLl6O6urqPZ5Irq281oLyxAwCQ4uAApPFRIL1nlIn7AfXPdv4Xp7+IiBxm0AFozZo1aG5uhlarPe8+nU6HlpYWrFmzxq7FkePl9Ux/jRnlD63G8aMN1mMx2AfUv109DdAMQEREjjPoALRlyxYsWrSo3/sXLVqEjz/+2C5FkfM44gT4gfBg1IGVNbSjrKEDCrnM1jNFRET2N+gAVFRUhPj4+H7vj42NRXFxsT1qIifKc1IDtNW0hGDIZUB5Ywcqmjqc8pruxHr8RVqsDgFqbtNFROQogw5Avr6+Awac4uJi+Pra9xBNciwhhK0BOtXB/T9WAWolUmIsr8VjMc63h/0/REROMegAlJWVhf/3//5fv/f/+9//RmZmpl2KIuc409SB+rYuKOUyTIw6v7fLUax9QHs5DdaLEOKc/X94/hcRkSMNOgA9+uijeP311/Hoo4/2Wu1VXV2NZcuWYcOGDXj00UcdUiQ5Rm6ZZfprYpQWGh/nnfMzI4k7QveluL4dVc2dUCnkyEgIlrocIiKPNugmg8svvxxr167Fww8/jBdeeAFarRYymQx6vR4+Pj54+eWXccUVVziyVrKzsztAO/dcLmtz78maVtS3GnjWVY9dpy2rv6bGBzk1kBIReaMhdVnee++9uP766/HOO+/g1KlTEEJg/PjxuOWWWxAbG+uoGslBnL0CzCrEX4Vx4QE4WdOK/cWNuDol0qmv76q4/w8RkfMMeZlJTEwMfvWrXzmiFnIik1kg38krwM6VmRTSE4AaGIBg6f/ZU8j+HyIiZxl0AHrppZf6vF2n02H8+PHIzs62W1HkeIW1rWjrMsFPpcDY8ACnv35mUgj+s7eU+wH1OFnTirrWLmh85EiLc+6UJBGRNxp0AHrhhRf6vL2pqQl6vR6zZs3C5s2bERLCzdvcgfUA1JQYHRRymdNf37oh4pEKPVoNRq/f82bXKUv/z4zEEKiV7P8hInK0IW2E2NdXY2MjTp06BbPZjN/97neOrJXsyFkHoPYnSueLuBBfmAVwoKRRkhpciXUDxJmj2f9DROQMdjkNfvTo0Vi9ejW++OILe1yOnODsCrAgyWrITLT8st9XVC9ZDa7AbBbYU2iZCpzFBmgiIqewSwACgPj4eFRVVdnrcuRABqMJRyubAcB2OrsUMpMse93sL/LuEaCjlc3Qd3QjQK3ElBj2/xAROYPdAlB+fj4SEhLsdTlyoOOVLeg2CQT7+SA2WLrjSzKTLKMdOWVN6Ow2SVaH1KzL3zOTQqBU2O2vJBERDWDQnafNzc193q7X63HgwAEsW7YMixcvtlth5DjnTn/JZM5vgLZKDPVDWIAada0G5JY1IctL+1+s/T/ZXvr+iYikMOgAFBTU/y9LmUyGu+++G48//rjdCiPHySmTbv+fc8lkMmQlheCT/ErsL27wygBkNJltWwFwA0QiIucZdAD6+uuv+7xdq9Vi3LhxCAgIwOHDh5GSkmK34sgx8mw7QEvfb5LZE4D2FjXgAamLkUD+Gcs2ADpfH0xy4oG0RETebtABaPbs2X3e3tLSgv/+97/417/+he+//x4mk/f2criDVoMRp2pbAUi7AszKei7YwZJGGE1mr+uBsZ7+PnN0COQS7MdEROSthv3b5ptvvsHixYsRFRWFP//5z7j88suxZ88ee9ZGDpBfrocQQEyQL0YFSn8IaXJkILQaJdq6zq5M8yZ72P9DRCSJIW2/W1VVhQ0bNuBf//oXmpubceutt8JgMODDDz/EpEmTHFUj2ZFUJ8D3RyGXYUZiCLYdr8G+ogaXGJVyFoPRhP3FPfv/jOX5X0REzjToEaAbbrgBycnJyMvLw4svvoiKigq8/PLLjqyNHMB2ArzEDdDnmtFzLIa3nQuWW6ZHZ7cZYQEqjJPgPDYiIm826AD02Wef4f/+7//w1FNP4brrroNCYZ/zitauXYvExERoNBpkZWVh3759/T52w4YNkMlkvb40Gs15jzt27BjmzZsHnU4Hf39/zJgxA6WlpXap193l9qwAc5URIODsuWD7ixtgNguJq3GeXact53/NHB0q6XYERETeaNABaOfOnWhpaUFGRgaysrLwt7/9DXV1dSN68bfffhtLly7FypUrcfDgQaSlpWHu3Lmoqanp9zlarRaVlZW2r5KSkl73nz59GhdffDEmTJiA7du3Iy8vD0888USfQcnb1LUacKapAzIZXGrH4ZRoHTQ+cjS2d+N0T4O2N7BugMjl70REzjfoADRz5ky89tprqKysxL333ouNGzciOjoaZrMZW7duRUtLy5BffM2aNbjnnntw5513YtKkSVi3bh38/Pywfv36fp8jk8kQGRlp+4qIiOh1/29/+1tce+21eO655zB16lSMGTMG8+bNQ3h4+JDr8zTW/p8xowIQqPGRtphzqJRyTIu3HIux10umwTq7TThU2gQAmDWG/T9ERM425FVg/v7+uOuuu7Bz507k5+dj2bJlWL16NcLDwzFv3rxBX6erqwsHDhzAnDlzzhYjl2POnDnYvXt3v89rbW1FQkIC4uLiMH/+fBw5csR2n9lsxieffILx48dj7ty5CA8PR1ZWFj788MMBazEYDGhubu715YlccfrLKtPL+oAOlDSiy2RGpFaDxFA/qcshIvI6I9p0JTk5Gc899xzKy8vx1ltvDem5dXV1MJlM543gRERE9HuoanJyMtavX49NmzbhzTffhNlsxqxZs1BeXg4AqKmpQWtrK1avXo2rr74aX3zxBW666Sb8+Mc/xo4dO/qtZdWqVdDpdLavuLi4Ib0Xd2FtgJbyANT+ZCaeDUBCeH4fkLX/Z9YY9v8QEUnBLrvOKRQK3Hjjjdi8ebM9Ltev7OxsLFq0COnp6Zg9ezbef/99jBo1Cq+++ioAywgQAMyfPx+/+tWvkJ6ejscffxzXX3891q1b1+91V6xYAb1eb/sqKytz6PuQghACeeXWEaAgaYvpw9T4YCjlMlQ1d6K8sUPqchzO2v8zk/0/RESSkGzb3bCwMCgUClRXV/e6vbq6GpGRkYO6ho+PD6ZOnYpTp07ZrqlUKs/bk2jixIkDrgJTq9XQarW9vjxNeWMHGtq64KOQYWJUoNTlnMdXpbBNzXl6H1CrwYjcnjA6iwGIiEgSkgUglUqFjIwMbNu2zXab2WzGtm3bkJ2dPahrmEwm5OfnIyoqynbNGTNmoKCgoNfjTpw4gYSEBPsV74as018To7RQK+2zhYG9WfcD2u/hAWh/cQNMZoG4EF/EBrP/h4hICkPaCdreli5disWLF2P69OnIzMzEiy++iLa2Ntx5550AgEWLFiEmJgarVq0CADz99NOYOXMmxo4di6amJjz//PMoKSnB3Xffbbvm8uXLsWDBAlx66aW4/PLLsWXLFnz00UfYvn27FG/RZZyd/nK9BmirrKQQvLqjEPuKPTsAWae/Zo3m6i8iIqlIGoAWLFiA2tpaPPnkk6iqqkJ6ejq2bNlia4wuLS2FXH52kKqxsRH33HMPqqqqEBwcjIyMDOzatavXlNdNN92EdevWYdWqVXjooYeQnJyM//3vf7j44oud/v5cSU5ZEwAgzQX7f6wyEkIgkwFFdW2oaelEeKBn7t3E/X+IiKQnE96w5GaImpubodPpoNfrPaIfyGQWmPL7z9HeZcIXv7oU4yNcrwfI6pq/fotjlc1Y+9NpuC41Supy7E7f3o30Z76AEMDe31yJCK1nhjwiIikM5fe3ZD1A5Dyna1vR3mWCn0qBMaNc+8ypLNt+QPUSV+IYe4vqIQQwepQ/ww8RkYQYgLyAdfprSowOCrlr7zkzw7ofUHGjxJU4xi5r/w+nv4iIJMUA5AXyXPAE+P7MSLIciXG8qhn6jm6Jq7G/PYU9/T9sgCYikhQDkBewrgBz5QZoq/BADZLC/CEEcKDEs1aD1bcacLzKcmbezNEhEldDROTdGIA8nMFowrFKy9lmrrwE/lzWYzE8bUPEPYWW9zMhMhChAWqJqyEi8m4MQB7uWGULuk0CIf4qxAb7Sl3OoHjqwajW87+4/J2ISHoMQB4u17b/j85tDt20BqD8cj06ukwSV2M/u239PwxARERSYwDycNYjMFzxANT+xAb7IkqngdEscKjUM1aDVek7UVjbBrkMyGIAIiKSHAOQh7M1QMe5R/8PAMhkMtsokKf0Ae0utEx/TY7WQefrI3E1RETEAOTBWjq7cbq2FYB7jQABZ/cD2u8h54Lt5v4/REQuhQHIg+Wf0UMIICbIF2FuturIuiP0wdJGdBnNElczctYNEGcyABERuQQGIA+WW2aZ/kp3gw0Qf2hseACC/XzQ2W3G4Qq91OWMSFlDO8obO6CUy2wjW0REJC0GIA+WZ2uAdp/+HyuZ7GxYcPfl8Nbpr9RYHQLUSomrISIigAHIo1kboN2t/8fKU/YDsi5/nzWGx18QEbkKBiAPVdtiwJmmDshkwBQ3HAECzgag/cUNMJmFxNUMjxCCGyASEbkgBiAPZZ3+GjsqwG2nXSZFaeGvUqCl04iCnjO03E1RXRuqmw1QKeTISAiWuhwiIurBAOShct18+gsAlAo5Mtx8Obx19dfU+CBofBQSV0NERFYMQB7KegRGuhttgNiXzETLqIm79gGx/4eIyDUxAHkgIcQ5K8CCJK1lpDKTLH0ze4saIIR79QEJIbCnZwSI/T9ERK6FAcgDlTV0oLG9GyqFHBOiAqUuZ0RSY3VQKeSoazWguL5d6nKG5ER1K+rbuqDxkbvlXkxERJ6MAcgDWQ9AnRgVCLXSvftOND4KW3jYV1QvbTFDZF39NSMxBCol/6oREbkS/lT2QJ4y/WXlrgej7ub0FxGRy2IA8kDWIzDSPGTaZUaS+60EM5kF9vQ0QGePZgAiInI1DEAexmgyI/9MTwBy0w0QfygjIRhymaW3qVLfIXU5g3KsshnNnUYEqJWYEuMZnwMRkSdhAPIwp2pb0dFtQoBaidGjAqQuxy4C1EpMjraECHdZDm/t/8lKCoFSwb9mRESuhj+ZPUxez/RXSowWCrlM4mrsx93OBWP/DxGRa2MA8jDWFWBpHtIAbeVOAajbZLbVyQBEROSaGIA8jC0AeUgDtNWMniMxTta0oqGtS+JqBpZ/Ro+2LhOC/HwwMVIrdTlERNQHBiAP0tltwvFKy6GhqR7SAG0V4q/CuHBLT5OrrwazTn/NTAqF3IOmIYmIPAkDkAc5VtkMo1kg1F+FmCBfqcuxO3eZBmP/DxGR62MA8iDWA1DT4oIgk3neyEOmG+wHZDCabPXNYgAiInJZDEAeJK/csgLM06a/rKx9QIfP6NFqMEpcTd9ySptgMJoRFqDG2HDP2IaAiMgTMQB5kBwPbYC2ig7yRWywL8wCOFjSKHU5fdp1zvSXJ47CERF5CgYgD9Hc2Y3C2jYAnrcE/lyu3ge0m8dfEBG5BQYgD3G4Z/orNtgXIf4qiatxnCwXDkAdXSYcKrWMTLH/h4jItTEAeQhPn/6ysvYB5ZQ3obPbJHE1vR0oaUS3SSBKp0FCqJ/U5RAR0QAYgDyE9QgMTzkAtT9JYf4IC1Cjy2i2NX27Cuv5X+z/ISJyfQxAHsJTj8D4IZlMZpsGc7Xl8Oz/ISJyHwxAHqCmpROV+k7IZUBKjGePAAHAjMRgAMBeF+oDajUYbSNS3ACRiMj1MQB5AOv019jwAPirlRJX43iZSZaAcaC4AUaTWeJqLPYXNcBkFogP8UNsMPt/iIhcHQOQB/CW6S+r5MhABGqUaOsy4VjP2WdSs/b/cPUXEZF7YADyALnWHaA9fAWYlUIus60G21tUL3E1Frb+HwYgIiK3wADk5oQQyLONAHl+/4+VK22I2NTehSMVzQDYAE1E5C4YgNxcaUM7mtq7oVLIMSFSK3U5TmMdAdpf3AAhhKS17C1qgBDAmFH+CNdqJK2FiIgGhwHIzVmnvyZGa6FSes/HOSVGB42PHI3t3ThV0yppLbt7zv+aNSZM0jqIiGjwvOc3pofKLWsCAKR70fQXAKiUckyNsyyH3yfxfkC7T7P/h4jI3TAAuTlr/0+ql6wAO5cr9AHVtRpQUG1ZiTaT/T9ERG6DAciNGU1mHD5jab5Ni/OuESCg98GoUvUB7elZ/TUhMtCjD6ElIvI0DEBu7GRNKzq6TQhQKzE6LEDqcpxuanwwlHIZKvWdKG/skKSGXez/ISJySwxAbsw6/TUlRge53PsO3/RVKTClp/dJqmmwPez/ISJySwxAbiynzLoBovdNf1llSngwapW+E4V1bZDLztZBRETugQHIjVlHgNK9sAHaKjNRukbo3YWW4y9SYnTQ+fo4/fWJiGj4GIDcVGe3CQVVltVH3nIERl+mJ4RAJgMK69pQ09Lp1NfedYrTX0RE7ooByE0dqWiG0SwQFqBGtM57dx/W+fkgOSIQAPB9caNTX9t2/heXvxMRuR0GIDd17vlfMpn3NUCfK0uC/YDKGtpR3tgB5TkHsxIRkftgAHJTedYT4L24/8cqM8kyArPXiQHIuvtzWlwQ/NVKp70uERHZBwOQm7IegeGNGyD+0Iwky5EYx6uaoe/odspr7jptaYCexf4fIiK3xADkhvQd3SisawPAESAACA/UICnMH0IAB0ocPwokhLBtgMj+HyIi9+QSAWjt2rVITEyERqNBVlYW9u3b1+9jN2zYAJlM1utLo+m/Cfi+++6DTCbDiy++6IDKpZHfM/0VH+LH4xd6nF0O7/hGaMuKMwNUSjmmJQQ7/PWIiMj+JA9Ab7/9NpYuXYqVK1fi4MGDSEtLw9y5c1FTU9Pvc7RaLSorK21fJSUlfT7ugw8+wJ49exAdHe2o8iWRazsAldNfVjNsjdD1Dn8t6+jPtPggaHwUDn89IiKyP8kD0Jo1a3DPPffgzjvvxKRJk7Bu3Tr4+flh/fr1/T5HJpMhMjLS9hUREXHeY86cOYMHH3wQ//nPf+Dj41mb1J1dARYkaR2uxLoSLK9cj44uk0Nfaw/P/yIicnuSBqCuri4cOHAAc+bMsd0ml8sxZ84c7N69u9/ntba2IiEhAXFxcZg/fz6OHDnS636z2Yw77rgDy5cvx+TJky9Yh8FgQHNzc68vV5bbcwRGmhdvgPhDscG+iNRqYDQLHCpz3DSY2SzO7v/DBmgiIrclaQCqq6uDyWQ6bwQnIiICVVVVfT4nOTkZ69evx6ZNm/Dmm2/CbDZj1qxZKC8vtz3m2WefhVKpxEMPPTSoOlatWgWdTmf7iouLG/6bcrDq5k5UNXdCLgNSYrRSl+MyZDKZ7TwuR+4HdKKmBQ1tXfD1UXAEjojIjUk+BTZU2dnZWLRoEdLT0zF79my8//77GDVqFF599VUAwIEDB/DXv/7V1iw9GCtWrIBer7d9lZWVOfItjIh1+fu48ED4qbj/zLmcEYCsx19MTwyGSul2f32IiKiHpD/Bw8LCoFAoUF1d3ev26upqREZGDuoaPj4+mDp1Kk6dOgUA+Pbbb1FTU4P4+HgolUoolUqUlJRg2bJlSExM7PMaarUaWq2215ersm6AyP1/zmcNQAdLG9FlNDvkNazTX+z/ISJyb5IGIJVKhYyMDGzbts12m9lsxrZt25CdnT2oa5hMJuTn5yMqKgoAcMcddyAvLw85OTm2r+joaCxfvhyff/65Q96HM51dARYkaR2uaOyoAAT7+aCz24zDFXq7X99kFtjD/h8iIo8g+RzK0qVLsXjxYkyfPh2ZmZl48cUX0dbWhjvvvBMAsGjRIsTExGDVqlUAgKeffhozZ87E2LFj0dTUhOeffx4lJSW4++67AQChoaEIDe39y8nHxweRkZFITk527puzMyGEbQQonQ3Q55HLZZieGIKtR6uxv6gB0+Ltu0fP0YpmtHQaEahWIiXadUcJiYjowiQPQAsWLEBtbS2efPJJVFVVIT09HVu2bLE1RpeWlkIuPztQ1djYiHvuuQdVVVUIDg5GRkYGdu3ahUmTJkn1FpympL4d+o5uqJRyJEcGSl2OS8pKsgSgfUUNuHf2GLte23r8RWZSCJQK9v8QEbkzyQMQADzwwAN44IEH+rxv+/btvf78wgsv4IUXXhjS9YuLi4dZmWuxTn9NitLCh7+A+2TtA9pf3ACzWUAuH1wj/GBw+TsRkefgb1E3Yt3/h9Nf/ZsUpYW/SoHmTiMKqlvsdt1uk9m2uowBiIjI/TEAuZE8HoFxQUrF2fO57LkcPq9cj/YuE4L8fDAxkv0/RETujgHITRhNZ1c2cQfogVmPxdhXbL8AtLun/2dmUqhdp9WIiEgaDEBu4kR1Kzq7zQhUK5EU6i91OS5tRuLZDRGFEHa5pm3/n7Gc/iIi8gQMQG7COv01JVbHEYgLSIsLgkohR22LAcX17SO+nsFowvfFlvPFskczABEReQIGIDdhXQHG6a8L0/gobDtl77dDH9Ch0iYYjGaEBagxNjxgxNcjIiLpMQC5CdsJ8GyAHhTrcvi9dghAu06fXf4+2PPliIjItTEAuYGOLpNtSTePwBiczCTLVNW+4voRX2vPaev5X5z+IiLyFAxAbuBopR4ms8CoQDWidBqpy3EL0+KDIJcBZQ0dqNR3DPs6HV0mHCpj/w8RkadhAHID505/cQpmcAI1PpgcbZkuHMl+QN+XNKDbJBCt0yAh1M9e5RERkcQYgNyArQGa019Dcu6xGMNl7f+Zyf4fIiKPwgDkBqwnwKdyBdiQnLsf0HDttvX/hNmlJiIicg0MQC5O396Noro2AEBqDFeADcWMRMuRGCeqW9HY1jXk57d0diP/jCV88vwvIiLPwgDk4vLONAEAEkL9EOyvkrYYNxN6zr49w5kG21/cAJNZICHUDzFBvvYuj4iIJMQA5OJs01/s/xkWax/QcKbBdp3q2f+Hq7+IiDwOA5CLyylrAsANEIcrawSN0Nbzvzj9RUTkeRiAXFwej8AYEWsj9OGKZrQajIN+XlN7F45WNgPgCBARkSdiAHJhVfpOVDcbIJcBk6O1UpfjlqKDfBEb7AuTWeBgSeOgn7ensAFCAGPDAxCu5eaTRESehgHIhVn3/xkfEQg/lVLaYtzYcPYD2n26DgBHf4iIPBUDkAvL4waIdpGZOPSDUa39Pzz/i4jIMzEAuTDrERipcWyAHgnrCFBOWRMMRtMFH1/bYsCJ6lYAQBZHgIiIPBIDkIsSQnAEyE6SwvwRFqBCl9Fs21ZgIHt6Rn8mRmkRwr2XiIg8EgOQiyqub0dzpxFqpRzJkYFSl+PWZDLZkPYDsp7/xf4fIiLPxQDkonJ79v+ZHK2Fj4If00hlDuFcsD3s/yEi8nj8zeqirCvAuAO0fczoGQE6UNIIo8nc7+Mq9R0oqmuDXAZkjg5xVnlERORkDEAuytqrksYGaLuYEKlFoEaJVoMRxypb+n2c9fT3KTE6aDU+ziqPiIicjAHIBXWbzDjccwo5G6DtQyGXYXqC5XT4fQPsB2Tt/5nJ6S8iIo/GAOSCTlS3wGA0I1CjRGKov9TleIzMJEuo2VdU3+f9QgjbCNCsMWFOq4uIiJyPAcgF2fb/idVBLpdJXI3nOLsjdCOEEOfdX9bQgTNNHVCeM1pERESeiQHIBXH/H8eYEqODxkeOhrYunK5tPe/+3YWW4y/S44Lgr+bRI0REnowByAXllltHgIKkLcTDqJRyTI2zjOz0dSyGbf8f9v8QEXk8BiAX09Flwolqyyql9LggaYvxQLZpsB8EoHP7fxiAiIg8HwOQizlSoYfJLBAeqEakTiN1OR7HGoD2FjX06gM6XduGmhYDVEo5psWz/4eIyNMxALmYnJ4doDn95RhT44OglMtQqe9EeWOH7Xbr6e8Z8cHQ+CikKo+IiJyEAcjFWDdATOcGiA7hp1IiJcbyvd1/zn5Au09bGqA5/UVE5B0YgFxMHo/AcLisHxyMajYL7Cm0/H+e/0VE5B0YgFxIU3sXiuvbAVj2ACLHsJ0M3zMCVFDdgoa2Lvj6KBg8iYi8BAOQC7FOfyWG+iHITyVxNZ5rekIIZDKgsLYNtS0G2+qvGUkhUCn5V4KIyBvwp70L4fSXc+j8fJAcEQjA0gdk2/9nNKe/iIi8BQOQC8kps54AHyRtIV7A2ge0p7Aee4us538xABEReQsGIBchhECu7QgM9v842oyeAPT+wTNo6TQiUK3E5GitxFUREZGzMAC5iKrmTtS2GKCQyzA5mgHI0TITLQGo1WAEAGSNDoFSwb8ORETegj/xXYT1BPjxEYHwVXEjPkcL12qQGOpn+/NM9v8QEXkVBiAXkcfpL6ezLocHgFljwiSshIiInI0ByEXY+n/YAO00mUmWUZ9gPx9MiAyUuBoiInImpdQFkGUnYuseQNwA0XmuSYnE1qNVuCw5HHK5TOpyiIjIiRiAXEBRfRtaOo1QK+UYH8GRCGfxVyvx6h3TpS6DiIgkwCkwF2Dt/0mJ0cGHK5GIiIgcjr9tXYB1BRinv4iIiJyDAcgFnN0AMUjSOoiIiLwFA5DEuk1mHK1oBsAVYERERM7CACSxgqoWGIxmaDXKXhvzERERkeMwAEns3P1/ZDIuxSYiInIGBiCJ5bEBmoiIyOkYgCRmHQFKZQM0ERGR0zAASai9y4gT1S0AgHQ2QBMRETkNA5CEjlQ0wyyACK0aEVqN1OUQERF5DQYgCeWWNQHg/j9ERETO5hIBaO3atUhMTIRGo0FWVhb27dvX72M3bNgAmUzW60ujOTt60t3djcceewxTpkyBv78/oqOjsWjRIlRUVDjjrQxJbs8BqNz/h4iIyLkkD0Bvv/02li5dipUrV+LgwYNIS0vD3LlzUVNT0+9ztFotKisrbV8lJSW2+9rb23Hw4EE88cQTOHjwIN5//30UFBRg3rx5zng7Q2IdAeIKMCIiIueS/DT4NWvW4J577sGdd94JAFi3bh0++eQTrF+/Ho8//nifz5HJZIiMjOzzPp1Oh61bt/a67W9/+xsyMzNRWlqK+Ph4+76BYWps60JpQzsAIDUmSNpiiIiIvIykI0BdXV04cOAA5syZY7tNLpdjzpw52L17d7/Pa21tRUJCAuLi4jB//nwcOXJkwNfR6/WQyWQICgrq836DwYDm5uZeX46Wd8Yy/ZUU5g+dn4/DX4+IiIjOkjQA1dXVwWQyISIiotftERERqKqq6vM5ycnJWL9+PTZt2oQ333wTZrMZs2bNQnl5eZ+P7+zsxGOPPYbbb78dWq22z8esWrUKOp3O9hUXFzeyNzYInP4iIiKSjuQ9QEOVnZ2NRYsWIT09HbNnz8b777+PUaNG4dVXXz3vsd3d3bj11lshhMArr7zS7zVXrFgBvV5v+yorK3PkWwAA5PEEeCIiIslI2gMUFhYGhUKB6urqXrdXV1f32+PzQz4+Ppg6dSpOnTrV63Zr+CkpKcFXX33V7+gPAKjVaqjV6qG/gWESQiCnzLoCjCNAREREzibpCJBKpUJGRga2bdtmu81sNmPbtm3Izs4e1DVMJhPy8/MRFRVlu80afk6ePIkvv/wSoaGhdq99JCr1nahrNUAhl2FyNAMQERGRs0m+Cmzp0qVYvHgxpk+fjszMTLz44otoa2uzrQpbtGgRYmJisGrVKgDA008/jZkzZ2Ls2LFoamrC888/j5KSEtx9990ALOHnlltuwcGDB/Hxxx/DZDLZ+olCQkKgUqmkeaPnsE5/JUcEQuOjkLYYIiIiLyR5AFqwYAFqa2vx5JNPoqqqCunp6diyZYutMbq0tBRy+dmBqsbGRtxzzz2oqqpCcHAwMjIysGvXLkyaNAkAcObMGWzevBkAkJ6e3uu1vv76a1x22WVOeV8D4fQXERGRtGRCCCF1Ea6mubkZOp0Oer1+wN6h4frpa3uw63Q9Vv94Cm7LdI19iYiIiNzdUH5/u90qMHdnNgvk9xyBkcoVYERERJJgAHKywro2tBiM0PjIMT4iQOpyiIiIvBIDkJNZG6BTonVQKvjtJyIikgJ/AzvZ2R2ggyStg4iIyJsxADlZbjlXgBEREUmNAciJuoxmHK20HLTKIzCIiIikwwDkRAVVLegymqHz9UFCqJ/U5RAREXktBiAnyu1pgE6N1UEmk0lbDBERkRdjAHIifUc3ND5yTn8RERFJjDtB98GRO0EbTWYYjGb4qyU/hYSIiMijDOX3N38LO5lSIef+P0RERBLjb2IiIiLyOgxARERE5HUYgIiIiMjrMAARERGR12EAIiIiIq/DAERERERehwGIiIiIvA4DEBEREXkdBiAiIiLyOgxARERE5HUYgIiIiMjrMAARERGR12EAIiIiIq/D0+D7IIQAADQ3N0tcCREREQ2W9fe29ff4QBiA+tDS0gIAiIuLk7gSIiIiGqqWlhbodLoBHyMTg4lJXsZsNqOiogKBgYGQyWRSl+OSmpubERcXh7KyMmi1WqnL8Xr8PFwLPw/Xws/DtTjy8xBCoKWlBdHR0ZDLB+7y4QhQH+RyOWJjY6Uuwy1otVr+QHEh/DxcCz8P18LPw7U46vO40MiPFZugiYiIyOswABEREZHXYQCiYVGr1Vi5ciXUarXUpRD4ebgafh6uhZ+Ha3GVz4NN0EREROR1OAJEREREXocBiIiIiLwOAxARERF5HQYgIiIi8joMQF7sm2++wQ033IDo6GjIZDJ8+OGHve4XQuDJJ59EVFQUfH19MWfOHJw8ebLXYxoaGrBw4UJotVoEBQXh//7v/9Da2trrMXl5ebjkkkug0WgQFxeH5557ztFvze2sWrUKM2bMQGBgIMLDw3HjjTeioKCg12M6OzuxZMkShIaGIiAgADfffDOqq6t7Paa0tBTXXXcd/Pz8EB4ejuXLl8NoNPZ6zPbt2zFt2jSo1WqMHTsWGzZscPTbc0uvvPIKUlNTbZu1ZWdn47PPPrPdz89DOqtXr4ZMJsMjjzxiu42fh3P9/ve/h0wm6/U1YcIE2/1u8XkI8lqffvqp+O1vfyvef/99AUB88MEHve5fvXq10Ol04sMPPxS5ubli3rx5IikpSXR0dNgec/XVV4u0tDSxZ88e8e2334qxY8eK22+/3Xa/Xq8XERERYuHCheLw4cPirbfeEr6+vuLVV1911tt0C3PnzhWvv/66OHz4sMjJyRHXXnutiI+PF62trbbH3HfffSIuLk5s27ZNfP/992LmzJli1qxZtvuNRqNISUkRc+bMEYcOHRKffvqpCAsLEytWrLA9prCwUPj5+YmlS5eKo0ePipdfflkoFAqxZcsWp75fd7B582bxySefiBMnToiCggLxm9/8Rvj4+IjDhw8LIfh5SGXfvn0iMTFRpKamiocffth2Oz8P51q5cqWYPHmyqKystH3V1tba7neHz4MBiIQQ4rwAZDabRWRkpHj++edttzU1NQm1Wi3eeustIYQQR48eFQDE/v37bY/57LPPhEwmE2fOnBFCCPH3v/9dBAcHC4PBYHvMY489JpKTkx38jtxbTU2NACB27NghhLB87318fMS7775re8yxY8cEALF7924hhCXQyuVyUVVVZXvMK6+8IrRare37/+tf/1pMnjy512stWLBAzJ0719FvySMEBweLf/7zn/w8JNLS0iLGjRsntm7dKmbPnm0LQPw8nG/lypUiLS2tz/vc5fPgFBj1qaioCFVVVZgzZ47tNp1Oh6ysLOzevRsAsHv3bgQFBWH69Om2x8yZMwdyuRx79+61PebSSy+FSqWyPWbu3LkoKChAY2Ojk96N+9Hr9QCAkJAQAMCBAwfQ3d3d6/OYMGEC4uPje30eU6ZMQUREhO0xc+fORXNzM44cOWJ7zLnXsD7Geg3qm8lkwsaNG9HW1obs7Gx+HhJZsmQJrrvuuvO+Z/w8pHHy5ElER0dj9OjRWLhwIUpLSwG4z+fBw1CpT1VVVQDQ6z9O65+t91VVVSE8PLzX/UqlEiEhIb0ek5SUdN41rPcFBwc7pH53Zjab8cgjj+Ciiy5CSkoKAMv3SqVSISgoqNdjf/h59PV5We8b6DHNzc3o6OiAr6+vI96S28rPz0d2djY6OzsREBCADz74AJMmTUJOTg4/DyfbuHEjDh48iP379593H/9+OF9WVhY2bNiA5ORkVFZW4qmnnsIll1yCw4cPu83nwQBE5GKWLFmCw4cPY+fOnVKX4vWSk5ORk5MDvV6P9957D4sXL8aOHTukLsvrlJWV4eGHH8bWrVuh0WikLocAXHPNNbb/n5qaiqysLCQkJOCdd95xm6DIKTDqU2RkJACc17VfXV1tuy8yMhI1NTW97jcajWhoaOj1mL6uce5r0FkPPPAAPv74Y3z99deIjY213R4ZGYmuri40NTX1evwPP48Lfa/7e4xWq3WbH1rOpFKpMHbsWGRkZGDVqlVIS0vDX//6V34eTnbgwAHU1NRg2rRpUCqVUCqV2LFjB1566SUolUpERETw85BYUFAQxo8fj1OnTrnN3w8GIOpTUlISIiMjsW3bNtttzc3N2Lt3L7KzswEA2dnZaGpqwoEDB2yP+eqrr2A2m5GVlWV7zDfffIPu7m7bY7Zu3Yrk5GROf51DCIEHHngAH3zwAb766qvzpg0zMjLg4+PT6/MoKChAaWlpr88jPz+/VyjdunUrtFotJk2aZHvMudewPsZ6DRqY2WyGwWDg5+FkV155JfLz85GTk2P7mj59OhYuXGj7//w8pNXa2orTp08jKirKff5+2KWVmtxSS0uLOHTokDh06JAAINasWSMOHTokSkpKhBCWZfBBQUFi06ZNIi8vT8yfP7/PZfBTp04Ve/fuFTt37hTjxo3rtQy+qalJREREiDvuuEMcPnxYbNy4Ufj5+XEZ/A/cf//9QqfTie3bt/daVtre3m57zH333Sfi4+PFV199Jb7//nuRnZ0tsrOzbfdbl5VeddVVIicnR2zZskWMGjWqz2Wly5cvF8eOHRNr167lMt9+PP7442LHjh2iqKhI5OXliccff1zIZDLxxRdfCCH4eUjt3FVgQvDzcLZly5aJ7du3i6KiIvHdd9+JOXPmiLCwMFFTUyOEcI/PgwHIi3399dcCwHlfixcvFkJYlsI/8cQTIiIiQqjVanHllVeKgoKCXteor68Xt99+uwgICBBarVbceeedoqWlpddjcnNzxcUXXyzUarWIiYkRq1evdtZbdBt9fQ4AxOuvv257TEdHh/jlL38pgoODhZ+fn7jppptEZWVlr+sUFxeLa665Rvj6+oqwsDCxbNky0d3d3esxX3/9tUhPTxcqlUqMHj2612vQWXfddZdISEgQKpVKjBo1Slx55ZW28CMEPw+p/TAA8fNwrgULFoioqCihUqlETEyMWLBggTh16pTtfnf4PGRCCGGfsSQiIiIi98AeICIiIvI6DEBERETkdRiAiIiIyOswABEREZHXYQAiIiIir8MARERERF6HAYiIiIi8DgMQEREReR0GICLqRSaT4cMPP3TY9YuLiyGTyZCTk+Ow1wCAn//857jxxhsd+hrO5qzvHZE3YAAi8iJVVVV48MEHMXr0aKjVasTFxeGGG24478BBT/DXv/4VGzZsGNJzHB3+iMh1KKUugIico7i4GBdddBGCgoLw/PPPY8qUKeju7sbnn3+OJUuW4Pjx41KXaFc6nU7qEtxGV1cXVCqV1GUQORVHgIi8xC9/+UvIZDLs27cPN998M8aPH4/Jkydj6dKl2LNnT6/H1tXV4aabboKfnx/GjRuHzZs397r/8OHDuOaaaxAQEICIiAjccccdqKurs91vNpvx3HPPYezYsVCr1YiPj8cf//jHPusymUy46667MGHCBJSWlgKwjMS88soruOaaa+Dr64vRo0fjvffe6/W8/Px8XHHFFfD19UVoaCh+8YtfoLW11Xb/D6fALrvsMjz00EP49a9/jZCQEERGRuL3v/+97f7ExEQAwE033QSZTGb78w9Zp6Hef/99XH755fDz80NaWhp2795te8zvf/97pKen93reiy++2Oua1vr+9Kc/ISIiAkFBQXj66adhNBqxfPlyhISEIDY2Fq+//vp5NRw/fhyzZs2CRqNBSkoKduzY0ev+C30+l112GR544AE88sgjCAsLw9y5c/t8r0SejAGIyAs0NDRgy5YtWLJkCfz9/c+7PygoqNefn3rqKdx6663Iy8vDtddei4ULF6KhoQEA0NTUhCuuuAJTp07F999/jy1btqC6uhq33nqr7fkrVqzA6tWr8cQTT+Do0aP473//i4iIiPNe12Aw4Cc/+QlycnLw7bffIj4+3nbfE088gZtvvhm5ublYuHAhbrvtNhw7dgwA0NbWhrlz5yI4OBj79+/Hu+++iy+//BIPPPDAgN+HN954A/7+/ti7dy+ee+45PP3009i6dSsAYP/+/QCA119/HZWVlbY/9+e3v/0tHn30UeTk5GD8+PG4/fbbYTQaB3zOD3311VeoqKjAN998gzVr1mDlypW4/vrrERwcjL179+K+++7Dvffei/Ly8l7PW758OZYtW4ZDhw4hOzsbN9xwA+rr6wEM7vOxfi9UKhW+++47rFu3bkh1E3kEu50rT0Qua+/evQKAeP/99y/4WADid7/7ne3Pra2tAoD47LPPhBBCPPPMM+Kqq67q9ZyysjIBQBQUFIjm5mahVqvFa6+91uf1i4qKBADx7bffiiuvvFJcfPHFoqmp6bwa7rvvvl63ZWVlifvvv18IIcQ//vEPERwcLFpbW233f/LJJ0Iul4uqqiohhBCLFy8W8+fPt90/e/ZscfHFF/e65owZM8Rjjz3W63U/+OCDgb49tvr/+c9/2m47cuSIACCOHTsmhBBi5cqVIi0trdfzXnjhBZGQkGD78+LFi0VCQoIwmUy225KTk8Ull1xi+7PRaBT+/v7irbfe6vXaq1evtj2mu7tbxMbGimeffVYIceHPx/q9mDp16oDvk8jTsQeIyAsIIYb0+NTUVNv/9/f3h1arRU1NDQAgNzcXX3/9NQICAs573unTp9HU1ASDwYArr7xywNe4/fbbERsbi6+++gq+vr7n3Z+dnX3en62rn44dO4a0tLReo1kXXXQRzGYzCgoK+hxt+uH7AoCoqCjb+xqqc68VFRUFAKipqcGECRMGfY3JkydDLj87EB8REYGUlBTbnxUKBUJDQ8+r8dzvjVKpxPTp022jYxf6fMaPHw8AyMjIGHSdRJ6IAYjIC4wbNw4ymWzQjc4+Pj69/iyTyWA2mwEAra2tuOGGG/Dss8+e97yoqCgUFhYO6jWuvfZavPnmm9i9ezeuuOKKQT1npAZ6XyO5lkwmAwDbteRy+Xmhs7u7e1D1jLTGC30+Vn1NhRJ5E/YAEXmBkJAQzJ07F2vXrkVbW9t59zc1NQ36WtOmTcORI0eQmJiIsWPH9vry9/fHuHHj4Ovre8Gl9ffffz9Wr16NefPmndfEC+C8xuw9e/Zg4sSJAICJEyciNze313v57rvvIJfLkZycPOj38kM+Pj4wmUzDfr7VqFGjUFVV1SsE2XPvnnO/N0ajEQcOHLB9by70+RCRBQMQkZdYu3YtTCYTMjMz8b///Q8nT57EsWPH8NJLL5033TSQJUuWoKGhAbfffjv279+P06dP4/PPP8edd94Jk8kEjUaDxx57DL/+9a/x73//G6dPn8aePXvwr3/967xrPfjgg/jDH/6A66+/Hjt37ux137vvvov169fjxIkTWLlyJfbt22drcl64cCE0Gg0WL16Mw4cP4+uvv8aDDz6IO+64o9/pr8FITEzEtm3bUFVVhcbGxmFf57LLLkNtbS2ee+45nD59GmvXrsVnn3027Ov90Nq1a/HBBx/g+PHjWLJkCRobG3HXXXcBuPDnQ0QWDEBEXmL06NE4ePAgLr/8cixbtgwpKSn40Y9+hG3btuGVV14Z9HWio6Px3XffwWQy4aqrrsKUKVPwyCOPICgoyNbP8sQTT2DZsmV48sknMXHiRCxYsKDfXptHHnkETz31FK699lrs2rXLdvtTTz2FjRs3IjU1Ff/+97/x1ltvYdKkSQAAPz8/fP7552hoaMCMGTNwyy234Morr8Tf/va3EXyHgL/85S/YunUr4uLiMHXq1GFfZ+LEifj73/+OtWvXIi0tDfv27cOjjz46otrOtXr1aqxevRppaWnYuXMnNm/ejLCwMACD+3yICJCJoXZHEhE5mEwmwwcffOBxR1kQkevgPweIiIjI6zAAERERkdfhMngicjmcmSciR+MIEBEREXkdBiAiIiLyOgxARERE5HUYgIiIiMjrMAARERGR12EAIiIiIq/DAERERERehwGIiIiIvM7/B8OfqTgw0JqpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(checkpoints, plot_aucs)\n",
    "plt.xlabel(\"Checkpoint number\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.savefig(f\"/mnt/scratch-lids/scratch/qixuanj/cxr_finetune_sd_{dataset_name}_base/figs/checkpoint_aucs.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710db531-34d1-46c8-be02-cccd8d7d089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For individual checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9a7a3d-0bf5-44d4-b92c-78e0361d4d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathologies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pathology \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mpathologies\u001b[49m): \n\u001b[1;32m      5\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma radiograph from dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with conditions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathology\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     images \u001b[38;5;241m=\u001b[39m pipe(prompt\u001b[38;5;241m=\u001b[39mprompt, \n\u001b[1;32m      7\u001b[0m                   strength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, guidance_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7.5\u001b[39m, num_inference_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[1;32m      8\u001b[0m                   num_images_per_prompt\u001b[38;5;241m=\u001b[39mnum_images)\u001b[38;5;241m.\u001b[39mimages\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pathologies' is not defined"
     ]
    }
   ],
   "source": [
    "num_images = 10 \n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "for i, pathology in enumerate(pathologies): \n",
    "    prompt = f\"a radiograph from dataset {dataset_name} with conditions {pathology}\"\n",
    "    images = pipe(prompt=prompt, \n",
    "                  strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                  num_images_per_prompt=num_images).images\n",
    "    images_t = []\n",
    "    for image in images: \n",
    "        image = np.array(image)\n",
    "        image = xrv.utils.normalize(image, maxval=255, reshape=True)\n",
    "        images_t.append(transform(image))\n",
    "    images_t = torch.stack(images_t)\n",
    "    images_t = torch.permute(images_t, (0, 2, 1, 3))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images_t)\n",
    "    outputs = convert_output(\"all\", outputs)\n",
    "    \n",
    "    labels = np.zeros((num_images, 8))\n",
    "    labels[:, i] = 1\n",
    "\n",
    "    all_outputs.append(np.array(outputs))\n",
    "    all_labels.append(labels)\n",
    "all_outputs = np.concatenate(all_outputs)\n",
    "all_labels = np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a28600f7-09c3-48c0-9713-a443e4c5d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5669642857142858\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(all_labels, all_outputs)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "630e236b-a47c-45c4-8fc0-075d71a877da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atelectasis</th>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consolidation</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lesion</th>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Finding</th>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "Atelectasis    0.535714\n",
       "Cardiomegaly   0.857143\n",
       "Consolidation  0.142857\n",
       "Edema          0.357143\n",
       "Lesion         0.535714\n",
       "Pneumonia      0.785714\n",
       "Pneumothorax   0.392857\n",
       "No Finding     0.928571"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_aucs = pd.DataFrame(roc_auc_score(all_labels, all_outputs, average=None), index=pathologies)\n",
    "task_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "733e8f02-6277-4362-b418-e27031517fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_binary = all_outputs.copy()\n",
    "all_outputs_binary[all_outputs_binary > 0.5] = 1\n",
    "all_outputs_binary[all_outputs_binary <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b4785ac-1a2f-4cdc-b7bd-cdcf480da8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(all_labels, all_outputs_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567727f-f860-43e3-8bdd-482ae3572168",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CXR Cross Dataset Classifier based evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee53c53-aea9-4124-b676-1ea539dd4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "from torcheval.metrics import MulticlassAUROC, MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81af3b4-1670-44b9-8895-660592762f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = torch.load(\"cxr_domain_classify/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f56cb53-0289-40fa-ad15-430eb97af00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591203be-d31b-4e8f-8bce-925e19a70a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'mimic': 0, 'chexpert': 1, 'padchest': 2, 'nih': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fb51e-5fa5-430b-be79-9e7829ab8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                            xrv.datasets.XRayResizer(224),\n",
    "                                            v2.ToDtype(torch.float32, scale=True),\n",
    "                                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9df41-7f23-47d0-ac98-da39ae608bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CXRDomain(Dataset):\n",
    "    def __init__(self, file_path, split, transform=None):\n",
    "        self.file_path = file_path \n",
    "        self.split = split \n",
    "        self.transform = transform \n",
    "        with open(self.file_path, \"rb\") as f: \n",
    "            prompt_files = pickle.load(f) \n",
    "        df = pd.concat([prompt_files['mimic'][split], prompt_files['chexpert'][split], \n",
    "                        prompt_files['padchest'][split], prompt_files['nih'][split]]).reset_index(drop=True)\n",
    "        self.label_mapping = {'mimic': 0, 'chexpert': 1, 'padchest': 2, 'nih': 3}\n",
    "        df['dataset_label'] = df['dataset_name'].map(self.label_mapping)\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        img_dirs = {\"mimic\": \"/data/healthy-ml/gobi1/data/MIMIC-CXR-JPG/files\", \n",
    "                    \"padchest\": \"/data/healthy-ml/gobi1/data/PadChest/images-224\", \n",
    "                    \"chexpert\": \"/data/healthy-ml/gobi1/data\", \n",
    "                    \"nih\": \"/data/healthy-ml/gobi1/data/ChestXray8/images\"}\n",
    "        \n",
    "        sample = self.df.iloc[idx]\n",
    "        img = cv2.imread(img_dirs[sample['dataset_name']] + \"/\" + sample['file_suffix'])\n",
    "        if self.transform: \n",
    "            img = self.transform(img) \n",
    "        return {'img': img, 'label': sample['dataset_label']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42de38-a3da-4ce8-a70d-0979ff450d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CXRDomain(\"cxr_prompt_files_base10000.pkl\", \"test\", transform)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d4cf3-30b6-497b-86ba-2d1e80c2e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle.eval()\n",
    "avg_loss = []\n",
    "task_outputs = []\n",
    "task_targets = []\n",
    "t = tqdm(test_dataloader)\n",
    "for batch_idx, sample in enumerate(t): \n",
    "    images, targets = sample['img'], sample['label']\n",
    "    images = torch.cat((images, images, images), 1)\n",
    "    images = images.to(\"cuda\")\n",
    "    targets = targets.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = oracle(images)\n",
    "\n",
    "    task_outputs.append(outputs.detach().cpu().numpy())\n",
    "    task_targets.append(targets.detach().cpu().numpy())\n",
    "    \n",
    "task_outputs = np.concatenate(task_outputs)\n",
    "task_targets = np.concatenate(task_targets)\n",
    "auc = MulticlassAUROC(num_classes=4)\n",
    "auc.update(torch.Tensor(task_outputs), torch.Tensor(task_targets))\n",
    "auc_result = auc.compute()\n",
    "print(auc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b463085d-95a6-49d2-b0c8-e231fa80c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting XRayResizer engine to cv2 could increase performance.\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                            xrv.datasets.XRayResizer(224),\n",
    "                                            v2.ToDtype(torch.float32, scale=True),\n",
    "                                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef04275-26b4-44d5-8428-9629d2fe2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CXRDomain(Dataset):\n",
    "    def __init__(self, file_path, split, transform=None):\n",
    "        self.file_path = file_path \n",
    "        self.split = split \n",
    "        self.transform = transform \n",
    "        with open(self.file_path, \"rb\") as f: \n",
    "            prompt_files = pickle.load(f) \n",
    "        df = pd.concat([prompt_files['mimic'][split], prompt_files['chexpert'][split], \n",
    "                        prompt_files['padchest'][split], prompt_files['nih'][split]]).reset_index(drop=True)\n",
    "        self.label_mapping = {'mimic': 0, 'chexpert': 1, 'padchest': 2, 'nih': 3}\n",
    "        df['dataset_label'] = df['dataset_name'].map(self.label_mapping)\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        img_dirs = {\"mimic\": \"/data/healthy-ml/gobi1/data/MIMIC-CXR-JPG/files\", \n",
    "                    \"padchest\": \"/data/healthy-ml/gobi1/data/PadChest/images-224\", \n",
    "                    \"chexpert\": \"/data/healthy-ml/gobi1/data\", \n",
    "                    \"nih\": \"/data/healthy-ml/gobi1/data/ChestXray8/images\"}\n",
    "        \n",
    "        sample = self.df.iloc[idx]\n",
    "        img = cv2.imread(img_dirs[sample['dataset_name']] + \"/\" + sample['file_suffix'])\n",
    "        if self.transform: \n",
    "            img = self.transform(img) \n",
    "        return {'img': img, 'label': sample['dataset_label']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219b9610-44da-449e-b18c-ed48bc1d8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CXRDomain(\"cxr_prompt_files_base10000.pkl\", \"test\", transform)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "101a284e-7698-46b1-a20d-32beea97d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2465/2465 [2:05:00<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8504)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oracle.eval()\n",
    "avg_loss = []\n",
    "task_outputs = []\n",
    "task_targets = []\n",
    "t = tqdm(test_dataloader)\n",
    "for batch_idx, sample in enumerate(t): \n",
    "    images, targets = sample['img'], sample['label']\n",
    "    images = torch.cat((images, images, images), 1)\n",
    "    images = images.to(\"cuda\")\n",
    "    targets = targets.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = oracle(images)\n",
    "\n",
    "    task_outputs.append(outputs.detach().cpu().numpy())\n",
    "    task_targets.append(targets.detach().cpu().numpy())\n",
    "    \n",
    "task_outputs = np.concatenate(task_outputs)\n",
    "task_targets = np.concatenate(task_targets)\n",
    "auc = MulticlassAUROC(num_classes=4)\n",
    "auc.update(torch.Tensor(task_outputs), torch.Tensor(task_targets))\n",
    "auc_result = auc.compute()\n",
    "print(auc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd40339-7d1b-4523-962f-faa859cb9830",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3649fb5-6f2f-492c-8070-69c4dcd0d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3000)\n",
      "tensor(0.4000)\n",
      "checkpoint 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n",
      "tensor(0.4000)\n",
      "checkpoint 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "checkpoint 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n",
      "tensor(0.1000)\n",
      "checkpoint 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n",
      "tensor(0.6000)\n"
     ]
    }
   ],
   "source": [
    "num_images = 10\n",
    "checkpoints = np.arange(200, 1001, 200)\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "keyword = \"cxr_transfer_sd_mimic_nih_1000_balanced\"\n",
    "condition_prompts = [\"Cardiomegaly, Pneumonia\", \"No Findings\"]\n",
    "\n",
    "results = {}\n",
    "for checkpoint in checkpoints:\n",
    "    results[checkpoint] = {}\n",
    "    print(\"checkpoint {}\".format(checkpoint))\n",
    "    \n",
    "    file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint-{checkpoint}\"\n",
    "    unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "    \n",
    "    pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.float16, safety_checker=None)\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "    source_dataset = keyword.split(\"_\")[3]\n",
    "    target_dataset = keyword.split(\"_\")[4]\n",
    "\n",
    "\n",
    "    # Source \n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for i, condition in enumerate(condition_prompts): \n",
    "        prompt = f\"a radiograph from dataset {source_dataset} with conditions {condition}\"\n",
    "        images = pipe(prompt=prompt, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=30, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            image = torch.Tensor(transform(np.array(image)))\n",
    "            image = torch.cat((image, image, image), 0)\n",
    "            images_t.append(image)\n",
    "        images_t = torch.stack(images_t)\n",
    "        images_t = images_t.to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = oracle(images_t)\n",
    "        \n",
    "        labels = np.repeat(label_mapping[source_dataset], num_images)\n",
    "    \n",
    "        all_outputs.append(outputs.detach().cpu().numpy())\n",
    "        all_labels.append(labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # auc = MulticlassAUROC(num_classes=4)\n",
    "    # auc.update(torch.Tensor(all_outputs), torch.Tensor(all_labels))\n",
    "    # source_auc_result = auc.compute()\n",
    "    \n",
    "    acc = MulticlassAccuracy()\n",
    "    acc.update(torch.Tensor(all_outputs), torch.Tensor(all_labels))\n",
    "    source_auc_result = acc.compute().item()\n",
    "    \n",
    "    # Target \n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for i, condition in enumerate(condition_prompts): \n",
    "        prompt = f\"a radiograph from dataset {target_dataset} with conditions {condition}\"\n",
    "        images = pipe(prompt=prompt, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=30, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            image = torch.Tensor(transform(np.array(image)))\n",
    "            image = torch.cat((image, image, image), 0)\n",
    "            images_t.append(image)\n",
    "        images_t = torch.stack(images_t)\n",
    "        images_t = images_t.to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = oracle(images_t)\n",
    "        \n",
    "        labels = np.repeat(label_mapping[target_dataset], num_images)\n",
    "    \n",
    "        all_outputs.append(outputs.detach().cpu().numpy())\n",
    "        all_labels.append(labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # auc = MulticlassAUROC(num_classes=4)\n",
    "    # auc.update(torch.Tensor(all_outputs), torch.Tensor(all_labels))\n",
    "    # target_auc_result = auc.compute()\n",
    "\n",
    "    acc = MulticlassAccuracy()\n",
    "    acc.update(torch.Tensor(all_outputs), torch.Tensor(all_labels))\n",
    "    target_auc_result = acc.compute().item()\n",
    "\n",
    "    results[checkpoint]['source_acc'] = source_auc_result\n",
    "    results[checkpoint]['target_acc'] = target_auc_result\n",
    "    print(source_auc_result) \n",
    "    print(target_auc_result)\n",
    "    \n",
    "result_dir = f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/eval\"\n",
    "if not os.path.exists(result_dir): \n",
    "    os.makedirs(result_dir)\n",
    "with open(result_dir + \"/checkpoint_oracle_acc.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4a255c87-32d0-4adf-846f-2db977e2efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  7.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "# Benchmark baseline model \n",
    "\n",
    "num_images = 10\n",
    "checkpoints = [4500]\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "keyword = \"cxr_finetune_sd_chexpert_base\"\n",
    "condition_prompts = [\"Cardiomegaly, Pneumonia\", \"No Findings\"]\n",
    "\n",
    "results = {}\n",
    "for checkpoint in checkpoints:\n",
    "    results[checkpoint] = {}\n",
    "    print(\"checkpoint {}\".format(checkpoint))\n",
    "    \n",
    "    file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint-{checkpoint}\"\n",
    "    unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "    \n",
    "    pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.float16)\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "    source_dataset = keyword.split(\"_\")[3]\n",
    "\n",
    "    # Source \n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for i, condition in enumerate(condition_prompts): \n",
    "        prompt = f\"a radiograph from dataset {source_dataset} with conditions {condition}\"\n",
    "        images = pipe(prompt=prompt, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=30, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            image = torch.Tensor(transform(np.array(image)))\n",
    "            image = torch.cat((image, image, image), 0)\n",
    "            images_t.append(image)\n",
    "        images_t = torch.stack(images_t)\n",
    "        images_t = images_t.to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = oracle(images_t)\n",
    "        \n",
    "        labels = np.repeat(label_mapping[source_dataset], num_images)\n",
    "    \n",
    "        all_outputs.append(outputs.detach().cpu().numpy())\n",
    "        all_labels.append(labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    auc = MulticlassAUROC(num_classes=4)\n",
    "    auc.update(torch.Tensor(all_outputs), torch.Tensor(all_labels))\n",
    "    source_auc_result = auc.compute()\n",
    "\n",
    "    results[checkpoint]['source_auc'] = source_auc_result\n",
    "    print(source_auc_result) \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df4df0-081b-4cf1-a3fc-542f209b8cdd",
   "metadata": {},
   "source": [
    "# Waterbirds Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4212817c-6ce0-441b-ab0d-3fee87219f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import BinaryAUROC, BinaryAccuracy, MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b2f5a9-50ed-46f9-acec-9324f075df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"waterbirds_results/oracle/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c1b2c7e-4a05-42e9-8f3e-b0bf942a60f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c12b7528-e0c9-4613-a924-bdcf167970af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import DiffusionPipeline, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fd209f9-1b63-47a7-8aeb-fdd12a80720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 0 (landbird), y = 1 (waterbird)\n",
    "transform = torchvision.transforms.Compose([v2.CenterCrop(224),\n",
    "                                            v2.RandomHorizontalFlip(),\n",
    "                                            v2.ToTensor(),\n",
    "                                            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "                                            ])\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6fc2d797-abc0-4a62-9629-ce4153fc2953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.88it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.5000), tensor(0.5000), tensor(0.1000), tensor(0.5000), tensor(0.9000)]\n",
      "0.56666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.92it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.6000), tensor(0.8000), tensor(0.5000), tensor(0.1000), tensor(1.)]\n",
      "0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.50it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8000), tensor(0.6000), tensor(0.6000), tensor(0.4000), tensor(0.4000), tensor(1.)]\n",
      "0.6333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.54it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.6000), tensor(0.8000), tensor(0.3000), tensor(0.1000), tensor(1.)]\n",
      "0.6166666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.81it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.), tensor(0.4000), tensor(0.8000), tensor(0.1000), tensor(0.3000), tensor(1.)]\n",
      "0.59999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.79it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.), tensor(0.6000), tensor(0.9000), tensor(0.5000), tensor(0.6000), tensor(1.)]\n",
      "0.76666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.62it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.), tensor(0.7000), tensor(0.8000), tensor(0.3000), tensor(0.4000), tensor(1.)]\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.56it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.), tensor(0.4000), tensor(0.9000), tensor(0.4000), tensor(0.7000), tensor(1.)]\n",
      "0.73333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.52it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.), tensor(0.5000), tensor(0.9000), tensor(0.5000), tensor(0.2000), tensor(0.9000)]\n",
      "0.6666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.60it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8000), tensor(1.), tensor(0.9000), tensor(0.2000), tensor(0.6000), tensor(1.)]\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "checkpoints = np.arange(200, 2001, 200)\n",
    "\n",
    "checkpoint_results = {}\n",
    "for checkpoint in checkpoints: \n",
    "    file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/waterbirds_finetune_sd_base/checkpoint-{checkpoint}\"\n",
    "    unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "    \n",
    "    pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.bfloat16, safety_checker=None,)\n",
    "    pipe.to(\"cuda\")\n",
    "    \n",
    "    num_images = 10\n",
    "    prompts = [\n",
    "        \"a photo of landbird with background of <wb-source-domain>\", \n",
    "        \"a photo of waterbird with background of <wb-source-domain>\",\n",
    "        \"a photo of landbird with background of blue ocean or lake\",\n",
    "        \"a photo of waterbird with background of green bamboo forest\",\n",
    "        \"a photo of waterbird with background of blue ocean or lake\",\n",
    "        \"a photo of landbird with background of green bamboo forest\",\n",
    "    ]\n",
    "\n",
    "    acc_results = []\n",
    "    for i, p in enumerate(prompts): \n",
    "        images = pipe(prompt=p, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            images_t.append(transform(image).to(\"cuda\"))\n",
    "        images_t = torch.stack(images_t)\n",
    "        outputs = model(images_t).detach().cpu().squeeze()\n",
    "        outputs = sigmoid(outputs)\n",
    "        if \"landbird\" in p: \n",
    "            targets = torch.full(outputs.size(), 0)\n",
    "        elif \"waterbird\" in p: \n",
    "            targets = torch.full(outputs.size(), 1)\n",
    "\n",
    "        acc = BinaryAccuracy()\n",
    "        acc.update(outputs, targets)\n",
    "        acc_results.append(acc.compute())\n",
    "    print(acc_results)\n",
    "    print(np.mean(np.array(acc_results)))\n",
    "    checkpoint_results[checkpoint] = acc_results\n",
    "with open(f\"/mnt/scratch-lids/scratch/qixuanj/waterbirds_finetune_sd_base/checkpoint_results2.pkl\", \"wb\") as f: \n",
    "    pickle.dump(checkpoint_results, f) \n",
    "for checkpoint, result in checkpoint_results.items(): \n",
    "    result = [x.item() for x in result]\n",
    "    print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "719da872-f6f7-46b2-8eb7-5c3acc1415fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 200: 0.567\n",
      "checkpoint 400: 0.65\n",
      "checkpoint 600: 0.633\n",
      "checkpoint 800: 0.617\n",
      "checkpoint 1000: 0.6\n",
      "checkpoint 1200: 0.767\n",
      "checkpoint 1400: 0.7\n",
      "checkpoint 1600: 0.733\n",
      "checkpoint 1800: 0.667\n",
      "checkpoint 2000: 0.75\n"
     ]
    }
   ],
   "source": [
    "for checkpoint, result in checkpoint_results.items(): \n",
    "    result = [x.item() for x in result]\n",
    "    print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b050c-3baf-48cb-8027-600dccca5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"waterbirds_finetune_sd_transfer_10\",\n",
    "    \"waterbirds_finetune_sd_transfer_50\",\n",
    "    \"waterbirds_finetune_sd_transfer_100\",\n",
    "    \"waterbirds_finetune_sd_transfer_500\",\n",
    "    \"waterbirds_finetune_sd_transfer_816\",\n",
    "           ]\n",
    "\n",
    "for keyword in keywords: \n",
    "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "    checkpoints = np.arange(200, 2001, 200)\n",
    "    \n",
    "    checkpoint_results = {}\n",
    "    for checkpoint in checkpoints: \n",
    "        file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint-{checkpoint}\"\n",
    "        unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "        \n",
    "        pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.bfloat16, safety_checker=None,)\n",
    "        pipe.to(\"cuda\")\n",
    "        \n",
    "        num_images = 10\n",
    "        prompts = [\n",
    "            \"a photo of landbird with background of <wb-source-domain>\", \n",
    "            \"a photo of waterbird with background of <wb-source-domain>\",\n",
    "            \"a photo of landbird with background of <wb-target-domain>\", \n",
    "            \"a photo of waterbird with background of <wb-target-domain>\",\n",
    "            \"a photo of landbird with background of blue ocean or lake\",\n",
    "            \"a photo of waterbird with background of green bamboo forest\",\n",
    "            \"a photo of waterbird with background of blue ocean or lake\",\n",
    "            \"a photo of landbird with background of green bamboo forest\",\n",
    "        ]\n",
    "    \n",
    "        acc_results = []\n",
    "        for i, p in enumerate(prompts): \n",
    "            images = pipe(prompt=p, \n",
    "                          strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                          num_images_per_prompt=num_images).images\n",
    "            images_t = []\n",
    "            for image in images: \n",
    "                images_t.append(transform(image).to(\"cuda\"))\n",
    "            images_t = torch.stack(images_t)\n",
    "            outputs = model(images_t).detach().cpu().squeeze()\n",
    "            outputs = sigmoid(outputs)\n",
    "            if \"landbird\" in p: \n",
    "                targets = torch.full(outputs.size(), 0)\n",
    "            elif \"waterbird\" in p: \n",
    "                targets = torch.full(outputs.size(), 1)\n",
    "    \n",
    "            acc = BinaryAccuracy()\n",
    "            acc.update(outputs, targets)\n",
    "            acc_results.append(acc.compute())\n",
    "        print(acc_results)\n",
    "        print(np.mean(np.array(acc_results)))\n",
    "        checkpoint_results[checkpoint] = acc_results\n",
    "    with open(f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint_results.pkl\", \"wb\") as f: \n",
    "        pickle.dump(checkpoint_results, f) \n",
    "    for checkpoint, result in checkpoint_results.items(): \n",
    "        result = [x.item() for x in result]\n",
    "        print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e6d52-4338-48a4-b592-ad5d94499c59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Oracle for only bird species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f83743a6-7d76-4f29-92eb-19262b9bee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle model for individual class \n",
    "with open(\"waterbirds_results/oracle_group/val_aucs.pkl\", \"rb\") as f: \n",
    "    val_aucs = pickle.load(f)\n",
    "val_aucs = [x.item() for x in val_aucs]\n",
    "epochs_map = np.arange(10, 101, 10)\n",
    "checkpoint = str(epochs_map[np.argmax(np.array(val_aucs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "011ab008-a219-4d12-a46b-a62290543eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cd2643d-13cc-4f0b-8de8-2ce0a424a9de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oracle model for individual class \n",
    "model = torch.load(f\"waterbirds_results/oracle_group/checkpoint{checkpoint}.pt\")\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f2b8c9ea-61f2-4f0a-b102-2cd8fcfd0b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 10.01it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.3000), tensor(0.9000), tensor(0.), tensor(0.), tensor(0.2000), tensor(1.)]\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.79it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:33<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.6000), tensor(0.7000), tensor(0.), tensor(0.), tensor(0.2000), tensor(0.9000)]\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.69it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.7000), tensor(0.), tensor(0.), tensor(0.6000), tensor(0.9000)]\n",
      "0.51666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.65it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8000), tensor(0.3000), tensor(0.), tensor(0.), tensor(0.2000), tensor(1.)]\n",
      "0.38333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.70it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8000), tensor(0.3000), tensor(0.), tensor(0.), tensor(0.7000), tensor(0.8000)]\n",
      "0.4333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.56it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.5000), tensor(0.), tensor(0.), tensor(0.3000), tensor(1.)]\n",
      "0.45000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.66it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.8000), tensor(0.5000), tensor(0.), tensor(0.), tensor(0.1000), tensor(1.)]\n",
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.29it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.5000), tensor(0.1000), tensor(0.), tensor(0.3000), tensor(1.)]\n",
      "0.46666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.63it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.9000), tensor(0.5000), tensor(0.), tensor(0.1000), tensor(0.4000), tensor(0.9000)]\n",
      "0.46666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 11.62it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.7000), tensor(0.6000), tensor(0.), tensor(0.), tensor(0.5000), tensor(0.9000)]\n",
      "0.44999996\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "checkpoints = np.arange(200, 2001, 200)\n",
    "num_images = 10\n",
    "\n",
    "checkpoint_results = {}\n",
    "for checkpoint in checkpoints: \n",
    "    file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/waterbirds_finetune_sd_base/checkpoint-{checkpoint}\"\n",
    "    unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "    pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.bfloat16, safety_checker=None,)\n",
    "    pipe.to(\"cuda\")\n",
    "    \n",
    "    prompts = [\n",
    "        \"a photo of landbird with background of <wb-source-domain>\", \n",
    "        \"a photo of waterbird with background of <wb-source-domain>\",\n",
    "        \"a photo of landbird with background of blue ocean or lake\",\n",
    "        \"a photo of waterbird with background of green bamboo forest\",\n",
    "        \"a photo of waterbird with background of blue ocean or lake\",\n",
    "        \"a photo of landbird with background of green bamboo forest\",\n",
    "    ]\n",
    "\n",
    "    acc_results = []\n",
    "    for i, p in enumerate(prompts): \n",
    "        images = pipe(prompt=p, \n",
    "                      strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                      num_images_per_prompt=num_images).images\n",
    "        images_t = []\n",
    "        for image in images: \n",
    "            images_t.append(transform(image).to(\"cuda\"))\n",
    "        images_t = torch.stack(images_t)\n",
    "        outputs = model(images_t).detach().cpu().squeeze()\n",
    "        outputs = sigmoid(outputs)\n",
    "        if \"landbird\" in p and \"<wb-source-domain>\" in p: \n",
    "            targets = torch.full((num_images, 1), 0).squeeze()\n",
    "        elif \"landbird\" in p and \"forest\" in p: \n",
    "            targets = torch.full((num_images, 1), 0).squeeze()\n",
    "        elif \"landbird\" in p and \"ocean\" in p: \n",
    "            targets = torch.full((num_images, 1), 1).squeeze()\n",
    "        elif \"waterbird\" in p and \"<wb-source-domain>\" in p: \n",
    "            targets = torch.full((num_images, 1), 3).squeeze()\n",
    "        elif \"waterbird\" in p and \"ocean\" in p: \n",
    "            targets = torch.full((num_images, 1), 3).squeeze()\n",
    "        elif \"waterbird\" in p and \"forest\" in p: \n",
    "            targets = torch.full((num_images, 1), 2).squeeze()\n",
    "\n",
    "        acc = MulticlassAccuracy()\n",
    "        acc.update(outputs, targets)\n",
    "        acc_results.append(acc.compute())\n",
    "    print(acc_results)\n",
    "    print(np.mean(np.array(acc_results)))\n",
    "    checkpoint_results[checkpoint] = acc_results\n",
    "with open(f\"/mnt/scratch-lids/scratch/qixuanj/waterbirds_finetune_sd_base/checkpoint_group_results2.pkl\", \"wb\") as f: \n",
    "    pickle.dump(checkpoint_results, f) \n",
    "for checkpoint, result in checkpoint_results.items(): \n",
    "    result = [x.item() for x in result]\n",
    "    print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9991d410-27af-403f-ac4e-675735e7cd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.bfloat16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 13.42it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m unet \u001b[38;5;241m=\u001b[39m UNet2DConditionModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/unet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m pipe \u001b[38;5;241m=\u001b[39m DiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, unet\u001b[38;5;241m=\u001b[39munet, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, safety_checker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma photo of landbird with background of <wb-source-domain>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma photo of waterbird with background of <wb-source-domain>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# \"a photo of landbird with background of green bamboo forest\",\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ]\n\u001b[1;32m     32\u001b[0m acc_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/diffusers/pipelines/pipeline_utils.py:427\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been loaded in 8bit and moving it to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    430\u001b[0m     module\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    434\u001b[0m ):\n\u001b[1;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/control/lib/python3.8/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keywords = [\n",
    "    \"waterbirds_finetune_sd_transfer_10\",\n",
    "    \"waterbirds_finetune_sd_transfer_50\",\n",
    "    \"waterbirds_finetune_sd_transfer_100\",\n",
    "    \"waterbirds_finetune_sd_transfer_500\",\n",
    "    \"waterbirds_finetune_sd_transfer_816\",\n",
    "           ]\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "checkpoints = np.arange(200, 2001, 200)\n",
    "num_images = 10\n",
    "\n",
    "for keyword in keywords:\n",
    "    checkpoint_results = {}\n",
    "    for checkpoint in checkpoints: \n",
    "        file_prefix = f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint-{checkpoint}\"\n",
    "        unet = UNet2DConditionModel.from_pretrained(f\"{file_prefix}/unet\")\n",
    "        pipe = DiffusionPipeline.from_pretrained(model_id, unet=unet, dtype=torch.bfloat16, safety_checker=None,)\n",
    "        pipe.to(\"cuda\")\n",
    "        \n",
    "        prompts = [\n",
    "            \"a photo of landbird with background of <wb-source-domain>\", \n",
    "            \"a photo of waterbird with background of <wb-source-domain>\",\n",
    "            \"a photo of landbird with background of <wb-target-domain>\", \n",
    "            \"a photo of waterbird with background of <wb-target-domain>\",\n",
    "            # \"a photo of landbird with background of blue ocean or lake\",\n",
    "            # \"a photo of waterbird with background of green bamboo forest\",\n",
    "            # \"a photo of waterbird with background of blue ocean or lake\",\n",
    "            # \"a photo of landbird with background of green bamboo forest\",\n",
    "        ]\n",
    "    \n",
    "        acc_results = []\n",
    "        for i, p in enumerate(prompts): \n",
    "            images = pipe(prompt=p, \n",
    "                          strength=0.9, guidance_scale=7.5, num_inference_steps=50, \n",
    "                          num_images_per_prompt=num_images).images\n",
    "            images_t = []\n",
    "            for image in images: \n",
    "                images_t.append(transform(image).to(\"cuda\"))\n",
    "            images_t = torch.stack(images_t)\n",
    "            outputs = model(images_t).detach().cpu().squeeze()\n",
    "            outputs = sigmoid(outputs)\n",
    "            if \"landbird\" in p and \"<wb-source-domain>\" in p: \n",
    "                targets = torch.full((num_images, 1), 0).squeeze()\n",
    "            elif \"landbird\" in p and \"<wb-target-domain>\" in p: \n",
    "                targets = torch.full((num_images, 1), 1).squeeze()\n",
    "            elif \"landbird\" in p and \"forest\" in p: \n",
    "                targets = torch.full((num_images, 1), 0).squeeze()\n",
    "            elif \"landbird\" in p and \"ocean\" in p: \n",
    "                targets = torch.full((num_images, 1), 1).squeeze()\n",
    "            elif \"waterbird\" in p and \"<wb-source-domain>\" in p: \n",
    "                targets = torch.full((num_images, 1), 3).squeeze()\n",
    "            elif \"waterbird\" in p and \"<wb-target-domain>\" in p: \n",
    "                targets = torch.full((num_images, 1), 2).squeeze()\n",
    "            elif \"waterbird\" in p and \"ocean\" in p: \n",
    "                targets = torch.full((num_images, 1), 3).squeeze()\n",
    "            elif \"waterbird\" in p and \"forest\" in p: \n",
    "                targets = torch.full((num_images, 1), 2).squeeze()\n",
    "    \n",
    "            acc = MulticlassAccuracy()\n",
    "            acc.update(outputs, targets)\n",
    "            acc_results.append(acc.compute())\n",
    "        print(acc_results)\n",
    "        print(np.mean(np.array(acc_results)))\n",
    "        checkpoint_results[checkpoint] = acc_results\n",
    "    with open(f\"/mnt/scratch-lids/scratch/qixuanj/{keyword}/checkpoint_group_results2.pkl\", \"wb\") as f: \n",
    "        pickle.dump(checkpoint_results, f) \n",
    "\n",
    "    print(keyword)\n",
    "    for checkpoint, result in checkpoint_results.items():\n",
    "        result = [x.item() for x in result]\n",
    "        print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c7413b2a-1aad-4ab5-9f06-483113b66fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/mnt/scratch-lids/scratch/qixuanj/waterbirds_finetune_sd_base/checkpoint_group_results2.pkl\", \"wb\") as f: \n",
    "    pickle.dump(checkpoint_results, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "af5bc2ba-fca7-40cc-9299-613a38f0881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 200: 0.4\n",
      "checkpoint 400: 0.4\n",
      "checkpoint 600: 0.517\n",
      "checkpoint 800: 0.383\n",
      "checkpoint 1000: 0.433\n",
      "checkpoint 1200: 0.45\n",
      "checkpoint 1400: 0.4\n",
      "checkpoint 1600: 0.467\n",
      "checkpoint 1800: 0.467\n",
      "checkpoint 2000: 0.45\n"
     ]
    }
   ],
   "source": [
    "for checkpoint, result in checkpoint_results.items(): \n",
    "    result = [x.item() for x in result]\n",
    "    print(f\"checkpoint {checkpoint}: {round(np.mean(np.array(result)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ce0d8-db0c-4840-ae16-4a8a013a54c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "control"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
